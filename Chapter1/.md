# 並行処理入門

並行処理とは何を指すのか？定義について明確にする。

### 一般的
- 1つ以上の処理が同時に発生する処理のことを指す

### Concurrency-in-Go的
- 本書で紹介する。（具体的には、Goは並行性をどのようにモデル化するか、このモデルで生じる問題は何か、それらの問題を解決するためにどのようにプリミティブを組み合わせていくかについてのみ）

並行性が重要になった理由、並行性が難しく入念な研究が必要となる理由、これらの課題があるにもかかわらずGoではその並行性のプリミティブを使ってなぜプログラムをきれいにそして早く書けるのか
上記を紐解くためには、「並行処理の歴史」を知る必要がある。

## 並列処理の歴史
- ムーアの法則
- アダムールの法則
- Spigotアルゴリズム
- Webスケール

## なぜ並行処理が難しいのか
- 競合状態
    ```
        var data int
        go func() {
            data++
        }()
        if data == 0 {
            fmt.Printf("the value is %v.\n", data)
        }
    ```
    - なにも表示されない。この場合3行目は5行目の前に実行される。
    - the value is 0が表示される。この場合、5-6行目は3行目の前に実行される。
    - the value is 1が表示される。この場合、5行目は、3行目の前に実行されるが、3行目は、6行目の前に実行される。

    ```
        var data int
        go func() {data++}()
        time.Sleep(1*time.Second)
        if data == 0 {
            fmt.Printf("the value is %v.\n", data)
        }
    ```
    競合が起こりにくくなっただけで、先の3つは起こりえる。
    スリープを加えたことによって、アルゴリズムの中に非効率なものを入れてしまった。

- アトミック性
    - 「コンテキスト」が重要
        例えば、あなたの処理のコンテキストの中ではアトミックな操作も、オペレーティングシステムというコンテキストではアトミックでないかもしれない。
        ある操作のアトミック性というのは、現在注目しているスコープによって変わりえる。
    
    - 「分割不能」と「中断不可」
        ```
            i++
        ```
        - iの値を取得する。
        - iの値を1増やす。
        - iの値を保存する。
        ひとつひとつの操作はそれぞれアトミックだが、これら3つを組み合わせるとコンテキストによってはアトミックでなくなる。
        アトミックな操作を組み合わせても必ずしも大きなアトミックな操作を作れるわけではない
        操作がアトミックになるかどうかは、アトミックにしたいコンテキストに依存する。
        コンテキストに1つも並行処理がないプログラムであれば、このコードはそのコンテキスト内ではアトミック
        もしiを他のゴルーチンに公開しないようなコンテキストのゴルーチンの場合、このコードはアトミック

    - アトミック性の重要性
        あるものがアトミックであれば、それを複数の平行なコンテキストで安全に扱えることが暗黙的に保障されているから
        この性質によって論理的に正しいプログラムを構成できるようになる。
        また、この性質は並行プログラムを最適化することにも使える。

- メモリアクセス同期
    データ競合があった場合で、2つの並行処理がメモリの同じ領域にアクセスしようとしていて、ともにアトミックでないアクセスだったとする。
    ```
        var data int
        go func() { data++ }()
        if data == 0 {
            fmt.Println("the value is 0.")
        } else {
            fmt.Printf("the value is %v.\n", data)
        }
    ```
        else句を追加して、dataの値に関係なく出力するようにした。これはデータ競合で、プログラムの出力は完全に非決定的
        実際、プログラム内で共有リソースに対する排他的なアクセスが必要な場所には名前がある。
        それは、クリティカルセクションと呼ばれている。上記の例の場合、次の3つがクリティカルセクション    

    - クリティカルセクション
        - ゴルーチン。data変数をインクリメントしている。
        - if文。dataの値が0かを確認している。
        - fmt.Printf文。dataの値を取ってきて出力している。    
        
    - クリティカルセクションを守る方法
        たくさんある。
        解決策の一つは、クリティカルセクション間でのメモリへのアクセスを同期すること
        ```
            var memoryAccess sync.Mutex                     //  ①
            var data int                    
            go func() {
                memoryAccess.Lock()                         //  ②
                data++
                memoryAccess.Unlock()                       //  ③
            }()
            
            memoryAccess.Lock()                             //  ④
            if data == 0 {
                fmt.Printf("the value is 0.\n")
            } else {
                fmt.Printf("the value is %v.\n", data)
            }
            memoryAccess.Unlock()                           //  ⑤
        ```
        1. data変数のメモリへのアクセスを同期するための変数を追加した。
        2. ここでゴルーチンはそのメモリに対する排他的アクセスを取得して、解放すると宣言するまではそれが続く
        3. ここでゴルーチンがメモリの排他的アクセスを開放する宣言をする。
        4. ここでまた制御文がdata変数のメモリに対して排他的アクセスを取得できるように宣言する。
        5. 再度ここでこのメモリに対する処理が終わったことを宣言する。

        data変数のメモリにアクセスしたいときは、はじめにLockを呼び、処理が終わったらUnlockを呼ぶことでメモリに対する同期的なアクセスが得られる。
        2つの呼び出しの間に書かれたコードはdataへの排他的アクセス権があると想定できる。
        データ競合は解決した
        しかし、まだ競合状態は解決していない
        このプログラムでの操作の順序はまだ非決定的
        ゴルーチンが先に実行されるか、あるいはifとelseのブロックが先に実行されるか
        パフォーマンスに悪影響がある。

- デッドロック、ライブロック、リソース枯渇
    - デッドロック
        デッドロックしたプログラムとは、すべての並行なプロセスがお互いの処理を待ちあっている状況になっているものを指す。
        この状態では、プログラムは外部の介入がない限り、決して動作する状態にならない
        ```
            type value struct {
                mu      sync.Mutex
                value   int
            }

            var wg sync.WaitGroup
            printSum := func(v1, v2 *value) {
                defer   wg.Done()
                v1.mu.Lock()                //  ①
                defer v1.mu.Unlock()        //  ②

                time.Sleep(2*time.Second)   //  ③
                v2.mu.Lock()
                defer v2.mu.Unlock()

                fmt.Printf("sum=%v\n", v1.value + v2.value)
            }

            var a, b value
            wg.Add(2)
            go printSum(&a, &b)
            go printSum(&b, &a)
            wg.Wait()
        ```
        
        1. ここで流入してくる値のためにクリティカルセクションに入る。
        2. ここでdefer文を使ってprintSumが値を戻す前にクリティカルセクションを抜ける。
        3. ここで処理の負荷をシミュレートするために一定時間スリープする。

        - デッドロックが起こる条件（Coffman条件）
            - 相互排他
                ある並行プロセスがリソースに対して排他的な権利をどの時点においても保持している。
            - 条件待ち
                ある並行プロセスはリソースの保持と追加のリソース待ちを同時に行わなければならない
            - 横取り不可
                ある並行プロセスによって保持されているリソースは、そのプロセスによってのみ解放される。
            - 循環待ち
                ある並行プロセス(P1)は、他の連なっている並行プロセス(P2)を待たなければならない
                そしてP2はP1を待っている

        - 例に挙げたプログラム
            1. printSum関数はaとbの両方に対して排他的アクセス権が必要なので、この条件を満たしている。
            2. printSumはaもしくはbのどちらかを保持していて、もう片方を待っているので、この条件を満たしている。
            3. ゴルーチンを横取りする方法は提供されていない。
            4. printSumの最初の呼び出しでは2番目の呼び出しを待っていて、逆もまた然り。

        これらの法則はデッドロックの予防にもつながる。
        これらの条件の少なくとも1つが真にならないようにすれば、デッドロックの発生を防げる。

    - ライブロック
        ライブロックとは平衡操作を行っているけれど、その操作はプログラムの状態を全く進めていないプログラムを指す。
        
        - 具体例
            廊下ですれ違う場面。相手は自分を活かせようとして片側によけるが、自分も片側によけた。
            しょうがないので、自分が逆側に避けると相手も同じことをしてしまう。
            これが永遠に続く

        ```
            cadence := sync.NewCond(&sync.Mutex{})
            go func() {
                for range time.Tick(1*time.Millisecond) {
                    cadence.Broadcast()
                }
            }()

            takeStep := func() {
                cadence.L.Lock()
                cadence.Wait()
                cadence.L.Unlock()
            }

            tryDir := func(dirName string, dir *int32, out *bytes.Buffer) bool {    //  1
                fmt.Fprintf(out, " %v", dirName)                                    //  2
                atomic.AddInt32(dir, 1)                                             //  3
                takeStep()

                if atomic.LoadInt32(dir) == 1 {
                    fmt.Fprint(out, ". Success!")
                    return true
                }

                takeStep()
                atomic.AddInt32(dir, -1)                                            //  4
                return false
            }

            var left, right int32
            tryLeft := func(out *bytes.Buffer) bool { return tryDir("left", &left, out) }
            tryRight := func(out *bytes.Buffer) bool { return tryDir("right", &right, out) }
        ```

        1. tryDirは、ある人がある方向に動いてみて、うまく動けたかを返す。書く方向は、その方向dir(direction)に動こうとしている人数で表される。
        2. 最初に、ある方向に動こうとしていることを、その方向に動く人数を1増やすことで宣言する。
        3. ライブロックの例を示すために、各人間は同じスピード、同じ歩調で動かなければならない。takeStepはすべての人間が同じ歩調で歩くのをシミュレートする。
        4. ここでこの人がこの方向にすすめないと気付いて諦めます。ここではその方向に動く人数を1減らすことで対応している。

        ```
            walk := func(walking *sync.WaitGroup, name string) {
                var out bytes.Buffer
                defer func() { fmt.Println(out.String) }
                defer walking.Done()

                fmt.Fprintf(&out, "%v is trying to scoot:", name)
                for i := 0; i < 5; i++ {                        //  1
                    if tryLeft(&out) || tryRight(&out) {        //  2
                        return
                    }
                }

                fmt.Fprintf(&out, "\n%v tosses her hands up in exasperation!", name)
            }

            var peopleInHallway sync.WaitGroup                  //  3
            peopleInHallway.Add(2)
            go walk(&peopleInHallway, "Alice")
            go walk(&peopleInHallway, "Barbara")
            peopleInHallway.Wait()
        ```

        1. このプログラムが終わるように、試行回数に作為的な上限を設けた。ライブロックがあるプログラムでは、そのような上限がなく、ないがゆえに問題になる。
        2. まず、ある人が左に行こうとする。もし失敗したら右に行こうとする。
        3. この変数はプログラムが両方の人間がお互いにすれ違えるようになる、あるいはすれ違うのをあきらめるまで待つ方法を提供している。

        2つ以上の並行プロセスが強調なしにデッドロックを予防しようとしている。
        廊下でお互いにどちらか一方だけが動けると決めれば、ライブロックは起こらない。
        一方が立ったまま、もう一方が異なる方向に避ければ、二人は歩き続けられる。

        ライブロックは、デッドロックよりも見つけるのが難しい。
        ライブロックはリソース枯渇と呼ばれるより大きな問題の一部。

    - リソース枯渇
        リソース枯渇とは、並行プロセスが仕事をするのに必要なリソースを取得できない状況を指す。
        ライブロックの話をしたときに、各ゴルーチンで枯渇していたリソースは共有ロック。
        ライブロックの議論とリソース枯渇を区別した理由は、ライブロックでは、全ての並行プロセスが等しくリソース枯渇していて、仕事が全くなされていないから。
        より広い意味でいえば、リソース枯渇は通常、1つ以上の貪欲な並行プロセスが不公平に他のプロセスが可能な限り仕事を効率的に行おうとしているのを妨げている、若しくは全くさせていないといった状況を暗に示す。

        ```
        var wg sync.WaitGroup
        var sharedLock sync.Mutex
        const runtime = 1*time.Second

        greedyWorker := func() {
            defer wg.Done()

            var count int
            for begin := time.Now(); time.Since(begin) <= runtime; {
                sharedLock.Lock()
                time.Sleep(3*time.Nanosecond)
                sharedLock.Unlock()
                count++
            }

            fmt.Printf("Greedy worker was able to execute %v work loops\n", count)
        }

        politeWorker := func() {
            defer wg.Done()

            var count int
            for begin := time.Now(); time.Since(begin) <= runtime; {
                sharedLock.Lock()
                time.Sleep(1*time.Nanosecond)
                sharedLock.Unlock()

                sharedLock.Lock()
                time.Sleep(1*time.Nanosecond)
                sharedLock.Unlock()

                sharedLock.Lock()
                time.Sleep(1*time.Nanosecond)
                sharedLock.Unlock()

                count++
            }

            fmt.Printf("Polite worker was able to execute %v work loops.\n", count)
        }

        wg.Add(2)
        go greedyWorker()
        go politeWorker()

        wg.Wait()
        ```

        ```
            Polite worker was able to execute 289777 work loops.
            Greedy worker was able to execute 471287 work loops
        ```

        貪欲なワーカーは、貪欲にワークループ全体で共有ロックを保持して、一方で行儀が良いワーカーは必要な時だけロックをしようとする。
        両方のワーカーともに同じ大きさのクリティカルセクションがあるとして、貪欲なワーカーのアルゴリズムがより効率的であるという判断はしない。
        そうではなく、ここでは貪欲なワーカーが不必要にクリティカルセクションを超えて共有ロックを広げていて、それによって（リソース枯渇が発生し）行儀のよいワーカーのゴルーチンが効率的に仕事を出来ていないと判断する。
        リソース枯渇を見つける技術は、計測。
        リソース枯渇は計測値のサンプリングとその記録について議論する良い題材。
        リソース枯渇を検知して解決する良い方法の1つは、仕事が終わったらログを首都力して、仕事の速度が期待通りになっているかを測定すること。

        ※バランスをみつける
        メモリに対するアクセスの同期はコストが高いので、ロックをとることがクリティカルセクションを超えてしまう方向に働くだろう。
        また、他方で他の並行プロセスがリソース枯渇になる危険がある。
        メモリアクセス同期を使うのであれば、パフォーマンスのために粗く同期をとるか、あるいは並行プロセス間の公平性のために細かく同期をとるか、その間にあるバランスを見つけなければならない。
        アプリケーションをチューニングする段階になったら、初めにメモリアクセス同期をクリティカルセクションだけにとどめておくことを強くお勧めする。
        同期がパフォーマンスの悪影響を及ぼすのであれば、いつでもスコープを広げてみるとよい
        スコープを狭めていくことは、広げることよりもずっと難しい。

        リソース枯渇はプログラムが非効率的、あるいは不適切にふるまってしまう原因となる。
        ある並行プロセスが貪欲すぎて完全に他の並行プロセスの仕事を邪魔するようであれば、より大きな問題を抱えることとなる。
        また、リソース枯渇がGoのプロセスの外からやってくる場合も考慮する必要がある。
        リソース枯渇はCPU、メモリ、ファイルハンドラー、データベース接続といったものにも適用されることを心に留める
        共有されなければならないあらゆるリソースは、リソース枯渇の候補になる。

- 並行処理の安全性を見極める。
    並行処理のコードを書く上で最も難しい部分、全ての問題の根底にあるもの = 人間
    既存のコードと向き合っている開発者にとって、どのコードが並行処理を行っているか、そしてコードを安全に扱う方法は常に明らかというわけではない。
    次の関数シグネチャを例に挙げる。

    ```
        //  CalculatePi は円周率のbegin桁目からend桁目の数字を計算します。
        func CalculatePi(begin, end int 64, pi *Pi)
    ```
    
    - この関数をつかってどうやってπの計算ができるのか。
    - この関数を複数並行起動するところも自分でやらなければいけないのか。
    - この関数は、自分でアドレスを渡しているPiのインスタンスを直接そうさしているようにも見える。このPiのメモリアクセスの動機は自分で行う必要があるのか、それともPi型が管理してくれるのか。

    コメントをすることでうまく疑問を解消できる。
    ```
        //  CalculatePi は円周率のbegin桁目からend桁目までの数字を計算します。
        //  
        //  内部的には、CalculatePi は FLOOR((end-begin)/2)個の並行プロセスを立ち上げて
        //  再帰的にCalculatePi を呼び出します。piへの書き込みの同期はPi構造体の内部で処理されます。
        func CalculatePi(begin, end int64, pi *Pi)
    ```

    コメントを読むとこの関数を呼び出すときは普通に呼び出せばよく、並行処理や同期処理に関しては何も気にしなくて良いとわかる。
    重要なのは、コメントがこれらの点に触れていること
    - 誰が並行処理を担っているのか。
    - 問題空間がどのように並行処理のプリミティブに対応しているか。
    - 誰が同期処理を担っているか。

    上記の関数に残るあいまいさは、設計を間違えていた影響によるものかもしれない。
    関数プログラミングでのやり方のように、関数では副作用がないようにすべきだったのかもしれない。
    
    ```
        func CalculatePi(begin, end int64) []uint
    ```
    この関数のシグネチャによって同期に関する疑問は解消する。
    しかし、以前として並行処理があるかどうかの疑問は残る。
    再度シグネチャを修正する。
    
    ```
        func CalculatePi(begin, end int64) <-chan uint
    ```
    ここではCalculatePiは少なくとも1つのゴルーチンをもっていて、私たちで他のゴルーチンを作って手を煩わせるべきでないとわかる。
    こうした修正は考慮に入れるべき思わぬ影響をパフォーマンスに与える可能性があり、そういう場合はパフォーマンスとコードの明瞭さのバランスの問題に立ち戻る。
    将来このコードにかかわる人々が正しく扱えるように、できる限りコードを明瞭にしておくことは重要。
    そしてパフォーマンスが重要であることは自明。
    両立させるのは難しい。
    
- 複雑さを前にした簡潔さ
    