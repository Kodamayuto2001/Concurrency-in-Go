# 並行性をどうモデル化するか：CSPとは何か

- 並行性と並列性
    ```
        並行性はコードの性質を指し、並列性は動作しているプログラムの性質を指す。
    ```
    ある2つの領域が並列に動作するようにコードを書いた時、プログラム内のその2つの領域は並列に動作しているようにみえるが、実際は、見た目にはわからないほど素早く逐次実行している。
    （CPUが1コアの場合）CPUのコンテキストは異なるプログラムの間で時間を共有するために切り替わり、十分に大まかな時間間隔では、複数のタスクが並列に実行しているようにみえる。
    同じプログラムのバイナリを2コアのマシンで実行すると、先のプログラムの2つの領域は実際に並列に動作している。

    1. 私たちが並列なコードを書いているのではなく、並列に走ってほしいと思う並行なコードを書いているだけである。並行性はプログラムのランタイムの性質であって、コードの性質ではない。
    2. 自分の書いた並行なコードが実際に並列に走っているかどうかを知らないで済む（そうあってほしい）私たちのプログラムの設計のもとにある抽象化層によってのみ可能。例えば言語自体の並行処理のプリミティブ、プログラムのランタイム、オペレーティングシステム、オペレーティングシステムが動作しているプラットフォーム（ハイパーバイザー、コンテナ、仮想マシンなどが該当）、さらに究極的にはCPUなどが当てはまる。
    3. 並列性は時間やコンテキストの機能である。コンテキストはある捜査がアトミックであると考えられる境界だと定義。もしコンテキストが5秒間に1秒かかる2つの操作を実行するのであれば、これらの操作が並列して実行されたものと考えることになるはず。もしコンテキストが1秒間だったら、操作を逐次的に実行する。
    コンテキストは時間に限定されない
    コンテキストはプログラムが稼働するプロセス、そのOSスレッド、あるいはマシンとも定義できる。
    あなたが定義するコンテキストに依存してアトミックな操作がアトミックであると考えられるように、平行な操作もあなたが定義するコンテキストに依存することで初めて正しいものとなる。
    すべて相対的なもの
    コンテキストがコンピュータだった場合、私のマシンで実行されているプロセスはあなたのマシンで動いているプロセスのロジックには影響を与えないと考えるのは妥当。
    両方のプロセスが計算機の処理を始めて、簡単な計算を実行した場合、私の計算結果はあなたの計算結果には影響を与えないはず。
    私たちのマシンはコンテキストで、各プロセスは平行な操作。
    先の例では、並行処理の操作を複数のマシン、オペレーティングシステム、プロセスといった観点で世界をとらえることで、並行操作を構成することにした。
    これらの抽象化によって正しい状態にできている。

    あるマシン上のプロセスは他のマシン上のプロセスに影響されないと想定してよい。（ここでは同じ分散システム上にいないと仮定）しかし、同じマシン上の2つのプロセスの場合、お互いのロジックに影響しないと想定してよいか？プロセスAがプロセスBが読み込んでいるファイルをいくつかを上書きしてしまうかもしれない、またセキュリティの十分考慮されていないOS上では、さらにプロセスAはプロセスBが読み込んでいるメモリを改変してしまうことがあるかもしれない。
    
    オペレーティングシステムのスレッドの境界で考えてみる。

- CSPとは何か
    CSPは「Communicating Sequential Processes」の略
    入力と出力は言語のプリミティブと考える必要がある。
    プロセス間の入出力、通信を構成するプリミティブ
    プロセス = 必要な入力を処理し、他のプロセスが消費する出力をもたらすロジックの塊をカプセル化するもの
    ```
        cardreader?cardimage                //  1
        lineprinter!lineimage               //  2
        X?(x,y)                             //  3
        DIV!(3*a+b, 13)                     //  4
        *[c:character; west?c → east!c]     //  5
    ```
    1. cardreaderからカードを読み込んで、その値（文字の配列）を変数cardimageに割り当てる。
    2. lineprinterに対して、そこに表示するためにlineimageの値を送る。
    3. Xという名前のプロセスから、1ペアの値を取得しxとyに割り当てる。
    4. DIVという名前のプロセスに、指定して2つの値を出力する。
    5. westから出力されたすべての文字を読み込み、1つずつeastに出力する。プロセスwestが終了したら繰り返しも終了する。

    「Guarded commands, nondeterminacy and formal derivation of programs（ガード付きコマンド、非決定性とプログラムの形式的導出）」
    Goのチャネル

    GoはCSPの原理を言語の中核として具現化し、この形式の並行プログラミングを大衆にもたらした最初の言語の1つ。
    メモリアクセス同期は本質的には悪いものではない。
    Goであってもある状況においてメモリを共有することはときには適切であるということが紹介される。
    しかしながら、共有メモリのモデルは正しく使うことが難しくなる。

    ゴルーチン ⇔ スレッド
    チャネル   ⇔ ミューテックス

- Goの並行処理における哲学
    通信によってメモリを共有し、メモリの共有によって通信してはいけない

    ```
        1 それはパフォーマンスクリティカルセクションですか？        
            yes:    プリミティブを使う      no:     次に続く

        2 データの所有権を移動しようとしていますか？               
            yes:    チャネルを使う          no:     次に続く

        3 構造体の内部の状態を保護しようとしていますか？
            yes:    プリミティブを使う      no:     次に続く

        4 複数のロジックを強調させようとしていますか？
            yes:    チャネルを使う          no:     プリミティブを使う

    ```

    2. データの所有権を移動しようとしていますか？
        何かしら結果を生成するコードがあり、その結果を別のコードに共有したい場合、これはデータの所有権を移動していることになる。
        ガベージコレクションをサポートしていない言語でのメモリの所有権の概念を知っているのであれば、これは同じ考え方。
        データには所有権があり、並行プログラムを安全にする方法の1つとして、一度に1つの並行処理のコンテキストのみがデータの所有権をもつようにする。
        チャネルを使うと、この糸をチャネルの型の形で表現することで、並行プログラムを安全にするという構想を伝えることができる。
        これを行う大きな利点の1つは、バッファ付きチャネルを作成して、コスタが低いインメモリのキューを実装し生産者(Producer)と消費者(Cosumer)を入りはなすことができること。
        他の大きな利点は、チャネルを使うことで暗黙的に並行処理のコードを他の並行処理のコードと構成可能にすること。

    3. 構造体の内部の状態を保護しようとしていますか？
        これはメモリアクセス同期を使うかどうかの分岐点であり、チャネルを使うべきでないかの非常に強い判断基準。
        メモリアクセス同期を使うことで、クリティカルセクションをロックする実装の複雑な詳細を呼び出し元から隠せる。
        次の例の型ではスレッドセーフであるけれど、その複雑さを呼び出し元に公開していない。
        ```
            type Counter struct {
                mu sync.Mutex
                value int
            }
            func (c *Counter) Increment() {
                c.mu.Lock()
                defer c.mu.Unlock()
                c.value++
            }
        ```
        Counter型のアトミック性のスコープを定義したといえる。
        Incrementへの呼び出しはアトミックであるといえる。
        ここで重要な言葉は内向き。
        型を超えてロックを公開していると思ったら、赤旗を上げるべき。
        ロックは小さなレキシカルスコープ内に制限するようにする。

    4. 複数のロジックを強調させようとしていますか？
        チャネルは性質としてメモリアクセス同期のプリミティブよりも構成可能であること。
        オブジェクトグラフの中にロックをまき散らすのは悪夢だが、チャネルをあらゆる場所で使うことは想定されていることで、推奨されている。
        チャネルを組み合わせて並行処理を設計することはできるが、ロックや値を返すメソッドを組み合わせて並行処理を設計するのは容易ではない。
        Goのselect文の中でチャネルを使ってやれば、ソフトウェアの複雑さを管理するのがとても簡単になるということが分かる。
        またチャネルのキューとしての能力とそれを安全に取り回せることにも気づくだろう。
        平行なコードがどのように動作しているか、なぜデッドロックや競合が発生しているか、なぜプリミティブを使っているのかがわからなくて苦戦しているのであれば、おそらくチャネルを使うべき良いサイン。

    1. それはパフォーマンスクリティカルセクションですか？
        これは「私のプログラムの性能を高くしたいのでミューテックスしか使いません」ということであれば問題はない。
        むしろプロファイルをとった個所があって、そこが他の個所よりもオーダーが数桁遅いのであれば、メモリアクセス同期のプリミティブを使うことで、負荷がかかったときでもクリティカルセクションがよりよく動作するだろう。
        チャネルもメモリアクセス同期を使っているので、遅くなりえるのがその理由。
        しかしながら、こうしたことを考慮する前に、パフォーマンスクリティカルセクションがある場合にはプログラムを再設計したほうが良いかもしれない

    この決定木によって、CSP形式の並行処理を使うか、メモリアクセス同期を使うかの基準が分かりやすくなった。
    OSスレッドを使う言語では、並行処理を抽象化する方法として便利な他のパターンや実践方法がある。
    例えば、スレッドプールなどはその例だろう。
    こうした抽象化はたいていOSスレッドの補強は強化をする目的で作られていて、経験上Goではあまり使うことはない。
    そうした抽象化が全くの役立たずということではない。
    しかし、Goではユースケースが非常に限られている。
    問題空間をゴルーチンに当てはめられるようにして、ワークフロー内の並行処理部分をうまく表現し、どんどんゴルーチンを起動しよう。
    ハードウェアがサポートする上限までゴルーチンを起動することになるより先に、プログラムの再設計をすることのほうが多い。
    Goの並行処理における哲学は次のようにまとめられる。
    簡潔さを求め、チャネルを出来る限り使い、ゴルーチンを湯水のように使おう。

    