# Goでの並行処理パターン

- 拘束
    並行なコードを扱うときに、安全な操作をするためにはいくつかの異なる方法が考えられる。
    これまで見てきたものは以下の通り。
    
    - メモリを共有するための同期のプリミティブ（例：sync.Mutex）
    - 通信による同期（例：チャネル）

    しかしながら、複数の並行プロセス内で暗黙的に安全な方法が他にもいくつかある。

    - イミュータブルなデータ
    - 拘束によって保護されたデータ

    ある意味で、イミュータブルなデータは暗黙的に「並行処理において安全」であり理想的
    各並行プロセスは同じデータに対して操作できるが、変更できない。
    新しいデータを作りたければ、そのデータをコピーしてから必要な変更を行う。
    これによって開発者がデータの中身を認識する負荷を軽減するだけでなく、クリティカルセクションを小さく（あるいはまったく無く）して、より速いプログラムにもなりえる。
    Goではメモリ内の値へのポインターの代わりに値のコピーを使るようなプログラムを書くことで実現できる。
    言語によっては、明示的にイミュータブルな値をもったポインターを扱うことができるが、Goではできない。

    拘束によっても開発者がデータの中身を認識する負荷を下げ、クリティカルセクションを小さくできる。
    並行処理で扱う値を拘束する技術は単純に値のコピーを渡すよりやや複雑になる。

    拘束は、情報をたった1つの並行プロセス空のみ得られることを確実にしてくれる単純だが強力な考え方。
    これが確実に行われたときには、並行プログラムは暗黙的に安全で、また同期が全く必要なくなる。
    拘束は2種類存在している。
    アドホックとレキシカルの2つ。

    アドホック拘束とは、拘束を規約（例えば言語コミュニティ、職場のチーム、あるいは触っているコードベースなどによって指定されている規則）によって達成した場合を指す。
    どのような規模のコミュニティにおいても、誰かがコードをコミットするたびに静的解析を実行してくれるようなツールがない限り、規則を守り続けるのは難しい。
    アドホック拘束の例を以下に示す。

    ```
        data := make([]int, 4)

        loopData := func(handleData chan<- int) {
            defer close(handleData)
            for i := range data {
                handleData <- data[i]
            }
        }

        handleData := make(chan int)
        go loopData(handleData)

        for num := range handleData {
            fmt.Println(num)
        }
    ```

    整数のスライスであるdataがloopData関数でもhandleDataチャネルに対する繰り返しでも利用できることが分かる。
    しかしながら、規約によってloopData関数のみからアクセスしている。
    しかし、コードが多くの人に手を入れられて、締め切りが迫ってくるにつれて、間違ったコードが混入し、拘束が破られて、問題が起きる。
    静的解析ツールはこういった類の問題を捕まえてくれるかもしれない。
    Goのコードベースに対する静的解析の導入は「多くの開発チームがそれを導入できる成熟度に到達できていない」ことを示す。
    レキシカル拘束を好む理由。
    これはコンパイラを駆使して拘束を強制するというもの。

    レキシカル拘束はレキシカルスコープを使って適切なデータと並行処理のプリミティブだけを複数の並行プロセスが使えるように公開することを示している。
    これによって誤った処理を書いてしまうことを不可能にしている。
    チャネルを必要とする並行プロセスにそのチャネルへの読み書きのうち必要な権限だけ公開する。

    ```
        chanOwner := func() <-chan int {
            results := make(chan int, 5)        //  1
            go func() {
                defer close(results)
                for i := 0; i <= 5; i++ {
                    results <- i
                }
            }()
            return results
        }

        consumer := func(results <-chan int) {  //  3
            for result := range results {
                fmt.Printf("Received: %d\n", result)
            }
            fmt.Println("Done receiving!")
        }

        results := chanOwner()                  //  2
        cosumer(results)
    ```

    1. チャネルをchanOwner関数のレキシカルスコープ内で初期化している。これによってresultsチャネルへの書き込みができるスコープを制限している。言い換えれば、このチャネルへの書き込み権限を拘束して、他のゴルーチンの書き込みを防いでいる。
    2. チャネルへの読み込み権限を受け取って、消費者に渡す。消費者は読み込み以外は何もしない。再度になるが、これによりメインゴルーチンにはこのチャネルへの読み込みだけが見えるように拘束する。
    3. intのチャネルの読み込み専用のコピーを受け取る。読み込み権限のみが必要であることを宣言することで、consumer関数内でのこのチャネルに対する操作を読み込み専用に拘束する。

    このように設定することで、この小さな例の中にあるresultチャネルは直接利用できなくなる。
    これは拘束の良い導入ではあるが、チャネルは並行安全なのでおもしろい例ではない。
    並行安全ではないデータ構造を使った高速の例。ここではbytes.Bufferを使う。

    ```
        printData := func(wg *sync.WaitGroup, data []byte) {
            defer wg.Done()

            var buff bytes.Buffer
            for _, b := range data {
                fmt.Fprintf(&buff, "%c", b)
            }
            fmt.Println(buff.String())
        }

        var wg sync.WaitGroup
        wg.Add(2)
        data := []byte("golang")
        go printData(&wg, data[:3])     //  1
        go printData(&wg, data[3:])     //  2
    ```

    1. dataの中の先頭の3バイトを含んだスライスを渡す。
    2. dataの中の後半の3バイトを含んだスライスを渡す。
    
    この例でprintDataはdataスライスの宣言の後にないので直接アクセスできず、引数としてbyteのスライスを渡してもらう必要がある。
    printDataを呼び出すゴルーチンでそれぞれ別の部分集合を渡しているので、起動したゴルーチンがそれぞれdataの一部しかアクセスできないように拘束している。
    レキシカルスコープによって、間違ったアクセスを不可能にした。
    またこうすることでメモリアクセスの動機や通信によるデータの共有を行う必要がなくなる。

    同期を利用できるのに、なぜ高速を使おうとするのか？
    パフォーマンス向上と、開発者に対する可読性の向上が理由。
    同期はコストが高くなり、使用を避けることができればクリティカルセクションを持たずに済む。
    またそれゆえに、同期のコストを書ける必要がなくなる。
    また同期を行うことで発生しうる問題すべてを回避できる。
    つまり開発者は単純にこういった類の問題を全く気にする必要がなくなる。
    さらにレキシカル拘束を利用する並行処理のコードは、そうでないコードに比較して一般的には理解しやすいものになるという利点がある。
    その理由は、レキシカルスコープのコンテキストの中では同期なコードを書けるから。

    拘束をきちんと作るのは難しいこともある。
    そのさいは、Goの並行処理のプリミティブを利用しなければならなくなる。


- for-selectループ
    ```
        for {           //  無限ループまたは何かのイテレーションを回す
            select {
                //  チャネルに対して何かを行う
            }
        }
    ```

    //  このパターンが出現するシナリオはいくつかある。

    - チャネルから繰り返しの変数を送出する。
        しばしば繰り返しが可能なものをチャネル上の変数に変換したいことがある。
        これは全く派手ではない。
        次のような見た目となる。
        ```
            for _, s := range []string{"a", "b", "c"} {
                select {
                case <-done:
                    return
                case stringStream <- s:
                }
            }
        ```

    - 停止シグナルを待つ無限ループ
        外部から停止の命令が来るまで無限に繰り返すゴルーチンを作るのはよくあること。
        パターンにはいくつかの変形がある。
        1つ目の形式はselect文を極力短くするもの。
        ```
            for {
                select {
                case <-done:
                    return
                default:
                }

                //  割り込みできない処理をする
            }
        ```

        doneチャネルが閉じられていなければ、select文を抜けてforループの本体の残りの処理を続ける。
        2つ目の形式ではselect文のdefault節に処理を埋め込む
        ```
            for {
                select {
                case <-done:
                    return
                default:
                    //  割り込みできない処理をする
                }
            }
        ```
        select文に入ったときに、doneチャネルが閉じられていなければ、代わりにdefault節を実行する。
        このパターンに関してはこれ以上のものはない。
        しかし、このパターンはどこでも見かけるので、ここで触れておく価値はあるだろう。

- ゴルーチンリークを避ける
    ゴルーチンの生成はコストが小さく容易。
    これこそが、Goをこれほどまでに生産的な言語たらしめている要素の1つ。
    ランタイムがゴルーチンをいかなる数のOSスレッドにもマルチプレキシングしてくれるので、我々が抽象化の層に関して気にする必要はほとんどない。
    しかし、少ないとはいえゴルーチンもコストがかかり、またゴルーチンはランタイムによってガベージコレクションされない。
    それゆえ、ゴルーチンのメモリフットプリントがどれほど小さいといっても、プロセス内にほったらかしにしてはならない。
    ゴルーチンを確実に片づけたらよいのか？

    なぜゴルーチンは存在するのか？
    ゴルーチンはお互いに並列に動作しているかどうかにかかわらず仕事の単位を表していること。
    ゴルーチンが終了に至るまでの流れはいくつかの種類がある。

    - ゴルーチンが終了を完了する場合
    - 回復できないエラーにより処理を続けられない場合
    - 停止するように命令された場合

    最初の2つの流れに関しては何もしないでも実行される（自分のアルゴリズム次第）
    しかし、キャンセル処理に関してはどうだろうか。
    このことはネットワーク降下より最も重要であると分かった。
    あなたがゴルーチンを起動すれば、それはたいてい何らかの整理されたやり方で他のいくつかのゴルーチンと強調しており、この相互に連結された状態はグラフで書き表せるだろう。
    子のゴルーチンが処理を続けるべきかどうかは他の多くのゴルーチンの状態を知ることが前提となる。
    親のゴルーチン（しばしばメインゴルーチン）がこういったコンテキストをすべて知ることで、子のゴルーチンに終了するよう命令できるようになるだろう。
    簡単なゴルーチンリークの例は以下の通り。
    ```
        doWork := func(strings <-chan string) <-chan interface{} {
            completed := make(chan interface{})
            go func() {
                defer fmt.Println("doWork exited.")
                defer close(completed)
                for s := range strings {
                    //  何か面白い処理
                    fmt.Println(s)
                }
            }()
            return completed
        }

        doWork(nil)
        //  もう少し何かしらの処理がここで行われる
        fmt.Println("Done.")
    ```
    この例では、メインゴルーチンがnilチャネルをdoWorkに渡している。
    それゆえ、stringsチャネルには実際には絶対に文字列が書き込まれることはなく、doWorkを含むゴルーチンはこのプロセスが生きている限りずっとメモリ内に残る。（もしdoWorkないのゴルーチンとメインゴルーチンをつなげていたらデッドロックしていただろう）
    
    このれいではプロセスの生存時間は短いが、実際のプログラムではゴルーチンは長時間稼働するプログラムの初めのほうで簡単に起動される。
    最悪の場合、メインゴルーチンは稼働し続ける限りゴルーチンを生成し続け、メモリ使用率をじわじわと高めていく。

    こうした問題を上手に軽減させるためには、ゴルーチンの親子間で親から子にキャンセルのシグナルを送れるようにする。
    慣習として、このシグナルは通常doneという名前の読み込み専用チャネルにする。
    親ゴルーチンはこのチャネルを子ゴルーチンに渡して、キャンセルさせたいときにチャネルを閉じる。
    その例が次の通り。
    ```
        doWork := func(done <-chan interface{}, strings <-chan strings) <-chan interface{} {        //  1
            terminated := make(chan interface{})
            go func() {
                defer fmt.Println("doWork exited.")
                defer close(terminated)
                for {
                    select {
                    case s := <-strings:
                        //  何か面白い処理
                        fmt.Println(s)
                    case <-done:        //  2
                        return
                    }
                }
            }
            return terminated
        }

        done := make(chan interface{})
        terminated := doWork(done, nil)

        go func() {         //  3
            //  1秒後に操作をキャンセルする
            time.Sleep(1 * time.Second)
            fmt.Println("Canceling doWork goroutine...")
            close(done)
        }()

        <-terminated        //  4
        fmt.Println("Done.")
    ```
    1. doneチャネルをdoWork関数に渡す。慣例として、このチャネルは第1引数にする。
    2. この行はどこにでも存在するfor-selectパターンを使っている。case文の1つでdoneチャネルからシグナルが送られたかどうかを確認している。もし送られていたら、ゴルーチンからreturnする。
    3. 1秒以上経過したらdoWorkの中で生成されたゴルーチンをキャンセルする他のゴルーチンを生成する。
    4. ここでdoWorkから生成されたゴルーチンがメインゴルーチンとつながる。

    出力結果は次の通り。
    ```
        Canceling doWork goroutine...
        doWork exited.
        Done.
    ```

    nilをstringsチャネルに渡しているにも関わらず、それでもゴルーチンは無事に終了している。
    先の例と違って、この例では2つのゴルーチンをつなげていて、それでもなおデッドロックしていない。
    その理由は、2つのゴルーチンをつながる前に、1秒経過後にdoWorkないのゴルーチンをキャンセルするための3つ目のゴルーチンを生成しているから。
    ゴルーチンリークを無事に取り除けた。

    先の例ではゴルーチンがチャネルでデータを受け取るケースに関してはうまく対応できた。
    しかし逆の状況ではどうだろうか。
    つまり、ゴルーチンがチャネルに対して書き込みを行おうとしてブロックしている状況。
    その問題を実際に示した例がこちら。
    ```
        newRandStream := func() <-chan int {
            randStream := make(chan int)
            go func() {
                defer fmt.Println("newRandStream closure exited.")  //  1
                defer close(randStream)
                for {
                    randStream <- rand.Int()
                }
            }()
            return randStream
        }

        randStream := newRandStream()
        fmt.Println("3 random ints:")
        for i := i; i <= 3; i++ {
            fmt.Printf("%d: %d\n", i, <-randStream)
        }
    ```
    1. ゴルーチンが無事に終了した場合にメッセージを表示する。

    実行結果はこちら
    ```
        3 random ints:
        1: 5577006791947779410
        2: 8674665223082153551
        3: 6129484611666145821
    ```

    出力結果を見てわかるように、deferされたfmt.Printlnの文は決して実行されない。
    3回繰り返しが実行された後に、次の乱数の整数をもう読み込まれていないチャネルに送信しようとしてゴルーチンはブロックしてしまう。生産者側に停止してよいと伝える方法がない。
    解決策は、受信側の例のように、生産者のゴルーチンに終了を伝えるチャネルを提供すること。

    ```
        newRandStream := func(done <-chan interface{}) <-chan int {
            randStream := make(chan int)
            go func() {
                defer fmt.Println("newRandStream closure exited.")
                defer close(randStream)
                for {
                    select {
                    case randStream <- rand.Int():
                    case <-done:
                        return
                    }
                }
            }()

            return randStream
        }

        done := make(chan interface{})
        randStream := newRandStream(done)
        fmt.Println("3 random ints:")
        for i := 1; i <= 3; i++ {
            fmt.Printf("%d: %d\n", i, <-randStream)
        }
        close(done)

        //  処理が実行中であることをシミュレート
        time.Sleep(1 * time.Second)
    ```

    実行すると次のようになる。
    ```
        3 random ints:
        1: 5577006791947779410
        2: 8674665223082153551
        3: 6129484611666145821
        newRandStream closure exited.
    ```

    ゴルーチンがきれいに片づけられた。
    ここまでで、ゴルーチンを確実にリークしないようにする方法を学んだので、次のような規約を明記できるだろう。
    もしあるゴルーチンがゴルーチンの生成の責任を持っているのであれば、そのゴルーチンを停止できるようにする積にもある。

    この規約によってプログラムが構成可能で自由にスケールできるようになる。
    ゴルーチンを停止させるやり方はゴルーチンの種類と目的によって変わるが、いずれもdoneチャネルを渡すという基本に基づく。

- orチャネル
    ときどき1つ以上のdoneチャネルを1つのdoneチャネルにまとめて、まとめてるチャネルのうちどれか1つのチャネルが閉じられたら、まとめたチャネルも閉じられるようにしたいと思うことがあるだろう。
    冗長にはなるが、select文を使ってまとめることには、全く問題はない。
    しかしながら、実行時にまとめるべきdoneチャネルがいくつあるかわからないこともある。
    こういった場合、あるいは1行で書きたい場合には、orチャネルパターンを使ってチャネルをまとめるとよいだろう。

    このパターンでは再帰とゴルーチンを使って合成したdoneチャネルを作れる。
    ```
        var or func(channels ...<-chan interface{}) <-chan interface{}
        or = func(channels ...<-chan interface{}) <-chan interface{} {  //  1
            switch len(channels) {
            case 0:         //  2
                return nil
            case 1:         //  3
                return channels[0]
            }

            orDone := make(chan interface{})
            go func() {     //  4
                defer close(orDone)
                switch len(channels) {
                case 2:     //  5
                    select {
                    case <-channels[0]
                    case <-channels[1]
                    }
                default:    //  6
                    select {
                    case <-channels[0]:
                    case <-channels[1]:
                    case <-channels[2]:
                    case <-or(append(channels[3:], orDone)...): //  6
                    }
                }
            }()
            return orDone
        }
    ```
    1. 関数orを定義している。この関数はチャネルの可変長引数のスライスを受け取り、1つのチャネルを返す。
    2. これは再帰関数なので、停止条件を決めなければならない。最初の条件は可変長引数のスライスが空の場合で、単純にnilチャネルを返す。これはチャネルを渡さなかった場合と同義。特に何かを行う合成チャネルを作ることは想定していない。
    3. 2つめの停止条件では、可変長のスライスが1つしか要素をもっていない場合で、このときその要素を返すだけ。
    4. ここが関数の本体で、再帰が発生する部分。ゴルーチンを作って、ブロックすることなく作ったチャネルにメッセージを受け取れるようにする。
    5. 再帰のやり方のせいで、orへの各再帰呼び出しは少なくとも2つのチャネルをもっている。ゴルーチンを制限するために、2つしかチャネルがなかった場合の特別な条件を設定する。
    6. スライスの3番目以降のチャネルから再帰的にorチャネルを作成して、そこからselectを行う。子の再帰関係はスライスの残りの部分をorチャネルに分解して、最初のシグナルが帰ってくる木構造を形成する。またorDoneチャネルも渡して、木構造の上位の部分が終了したら下位の部分も終了するようにしている。

    この関数はかなり簡潔になっていて、任意の数のチャネルを1つのチャネルにまとめることができる。
    そしてまとめているチャネルのどれか1つでも閉じたり書き込まれたら、すぐに合成されたチャネルが閉じるようになっている。
    この関数の使い方を見てみよう。
    この例では異なる設定時間を過ぎたら閉じたられるチャネルを複数受け取り、それらをor関数を使って最終的に閉じられる1つのチャネルにまとめる。
    
    ```
        sig := func(after time.Duration) <-chan interface{} {   //  1
            c := make(chan interface{})
            go func() {
                defer close(c)
                time.Sleep(after)
            }()
            return c
        }

        start := time.Now()     //  2
        <-or(
            sig(2*time.Hour),
            sig(5*time.Minute),
            sig(1*time.Second),
            sig(1*time.Hour),
            sig(1*time.Minute),
        )

        fmt.Printf("done after %v", time.Since(start))
    ```
    1. この関数は単純にafterで指定された時間が経過したら閉じられるチャネルを生成する。
    2. or関数から返されるチャネルがいつブロックされ始めたかを大まかに追跡にする。
    3. チャネルにかかった時間を表示する。

    このプログラムを実行すると次の結果が表示される。
    ```
        done after 1.0006745s
    ```

    orを呼び出すときに、閉じるのに様々な時間がかかる複数のチャネルを渡したにも関わらず、1秒経過後に閉じるチャネルがorの呼び出しで合成されたチャネル全体を閉じた、という結果に注目
    この結果は、or関数が作る木構造の中で1秒経過後に閉じるチャネルが中程にあるにもかかわらず、そのチャネルが常に最初に閉じるため、依存しているチャネルもまた閉じることによる。

    この簡潔な書き方は追加のゴルーチン（f(x)=[x/2]という式でxはゴルーチンの数とする）というコストを払って成立しているが、Goの強みの1つはゴルーチンを素早く生成し、スケジュール管理し、実行できることであり、またGo自体も問題を正しく記述するためにゴルーチンを使用することを積極的に推奨している。
    ここで生成されるゴルーチンの数を気にするのはおそらく早すぎる最適化。
    さらに言えば、コンパイル時に扱うdoneチャネルがいくつあるかわからないのであれば、そもそもほかにdoneチャネルをまとめる方法はない。

    このパターンは、システム内で複数のモジュールを組み合わせる際のつなぎ目として利用すると便利。
    こうしたつなぎ目では、コールスタック内でゴルーチンの木構造をキャンセルする条件が複数になる傾向がある。
    or関数を使うことによって、単純にこれらを組み合わせてコールスタックに伝える。
    
- エラーハンドリング
    並行処理のプログラムでは、正しくエラーハンドリングをするのが難しいことがある。
    ときどき、様々なプロセスがどのように情報を共有して協力しあっているのかに考え巡らせることに時間をかけすぎてしまい、エラーが発生した状態を正常に扱う方法について配慮し忘れてしまう。
    Goが、人気のある例外処理機構を採用しないことを決めたとき、Goはエラーハンドリングが重要で、プログラムを書く時にはエラーの伝播について、アルゴリズムを考えるときと同じくらいの注意を払うべきであると宣言した。
    その精神を踏まえて、複数の並行処理プロセスがある場合に、どうエラーハンドリングすればよいか見ていこう。

    エラーハンドリングについて考えるときに最も根本的な疑問は、「誰がそのエラーを処理する責任を持つべきか」である。
    プログラムはそのエラーの伝播をコールスタックの途中のどこかで止めて、実際にそのエラーを受けて何かを行う必要がある。
    こうした作業には何が責任を果たすべきなのだろうか。

    並行処理プロセスでは、この疑問はもう少し複雑になる。
    並行処理プロセスは、その親や兄弟から独立して処理を実行しているため、そのプロセスがそのエラーに対して何を行うのが正しいかを導き出すのが難しくなるから。
    次のコードを見てほしい。
    ```
        checkStatus := func(
            done <-chan interface{},
            urls ...string,
        ) <-chan *http.Response{
            responses := make(chan *http.Response)
            go func() {
                defer close(response)
                for _, url := range urls {
                    resp, err := http.Get(url)
                    if err != nil {
                        fmt.Println(err)        //  1
                        continue
                    }
                    select {
                    case <-done:
                        return
                    case response <- resp:
                    }
                }
            }()
            return responses
        }

        done := make(chan interface{})
        defer close(done)

        urls := []string{"https://www.google.com", "https://badhost"}
        for response := range checkStatus(done, urls...) {
            fmt.Printf("Response: %v\n", response.Status)
        }
    ```
    1. ゴルーチンが全力を尽くした結果エラーがあることを表示した。他に何ができるだろう。エラーは戻せない。エラーはいくつから多すぎることになるのだろうか。このゴルーチンはHTTPリクエストを発行し続けるだろうか。

    このコードを実行すると次の結果となる。
    ```
        Response: 200 OK
        Get https://badhost: dial tcp: lookup badhost: no such host
    ```

    ゴルーチンはこの件に関して選択しを与えられていないことがわかるだろう。
    単純にエラーを内部でなかったことにするわけにいかないので、唯一妥当なことを行っているだけ。
    つまり、エラーを表示して、何かがその表示で注意を払ってくれることを期待しているだけ。
    ゴルーチンをこのような無様な状態にさせてはいけない。
    ここで提案したいのは、甘心事を分けること。
    一般的に並行プロセスはエラーを、プログラムの状態を完全に把握していて何をすべきかをより多くの情報に基づいて決定できる別の箇所へと送るべき。
    次の例はこの問題の正しい解決策を示している。

    ```
        type Result struct {        //  1
            Error error
            Response *http.Response
        }
        checkStatus := func(done <-chan interface{}, urls ...string) <-chan Result {        //  2
            results := make(chan Result)
            go func() {
                defer close(results)

                for _, url := range urls {
                    var result Result
                    resp, err := http.Get(url)
                    result = Result{Error: err, Response: resp}     //  3
                    select {
                    case <-done:
                        return
                    case results <- result:     //  4
                    }
                }
            }()
            return results
        }

        done := make(chan interface{})
        defer close(done)

        urls := []string{"https://www.google.com", "https://badhost"}
        for result := range checkStatus(done, urls...) {
            if result.Error != nil {        //  5
                fmt.Printf("error: %v", result.Error)
                continue
            }

            fmt.Printf("Response: %v\n", result.Response.Status)
        }
    ```
    1. *http.Responseとゴルーチンの中の繰り返しで発生しうるerrorを囲む型を作る。
    2. この行は各繰り返しの結果を取得するために読み込まれるチャネルを返す。
    3. ResultのインスタンスをErrorとResponseのフィールドを初期化して作成する。
    4. ここでResultをチャネルに書き込む。
    5. メインゴルーチン内でcheckStatusで起動されたゴルーチンから発生するエラーを賢く、そしてより大きなプログラムのコンテキストすべてを理解したうえで扱える。

    このコードは次のような結果となる。
    ```
        Response: 200 OK
        error: Get https://badhost: dial tcp: lookup badhost: no such host
    ```

    ここで触れるべき重要な点は、取得されるであろう結果とエラーを対にするという方法。
    この型はcheckStatusというゴルーチンから生成されうる出力のすべてをまとめていて、これによってエラーが発生したときにメインゴルーチンが何をすべきか決定できる。
    広い視点で見れば、エラーハンドリングの懸念と生産者のゴルーチンを無事に切り分けられたということ。
    生産者のゴルーチンを生成したゴルーチン（この例の場合はメインゴルーチン）は実行中のプログラムに関してより多くのコンテキストをもっていて、エラーにいたして賢明な判断を下せるので、この状況は望ましいこと。

    先の例ではエラーを単純にstdioに出力したが、何か他のこともできそう。
    少しプログラムを変更して、3つ以上のエラーが発生したら処理を停止して状態を確認できるようにしよう。
    ```
        done := make(chan interface{})
        defer close(done)

        errCount := 0
        urls := []string{"a", "https://www.google.com", "b", "c", "d"}
        for result := range checkStatus(done, urls...) {
            if result.Error != nil {
                fmt.Printf("error: %v\n", result.Error)
                errCount++
                if errCount >= 3 {
                    fmt.Println("Too many errors, breaking!")
                    break
                }
                continue
            }
            fmt.Printf("Response: %v\n", result.Response.Status)
        }
    ```

    このコードは次のような出力を生成する。
    ```
        error: Get a: unsupported protocol scheme ""
        Response: 200 OK
        error: Get b: unsupported protocol scheme ""
        error: Get c: unsupported protocol scheme ""
        Too many errors, breaking!
    ```
    
    checkStatusからエラーが返されてゴルーチン内で対処されなかったので、エラーハンドリングもGoのよくあるパターンに沿っているのが分かる。
    これは単純な例だが、メインゴルーチンが複数のゴルーチンからの結果を取りまとめて、子ゴルーチンを継続させるか中断するかを決めるより複雑なルールを作り上げるような状況も想像に難くない。
    繰り返しになるが、この説での主な教訓は、エラーはゴルーチンから返される値を構築する際の第一級市民としてとらえられるべきであるということである。
    もし今書いているゴルーチンがエラーを生成するのであれば、それは正常系の結果と強くむずびつけて（ちょうど通常の同期関数と同じように）正常系と同じ経路を使って渡されるべきである。

- パイプライン
    プログラムを書く際、関数や構造体、メソッドなどの形で抽象化を行うはず。
    なぜこうした抽象化をするのか。
    理由の一部としては、プログラム全体の流れに影響しない細かな部分を抽出するため。
    そしてほかの理由としてはある領域に取り込む際に他の領域に影響を与えないため。
    システム変更を加えなければならないとき、1つの論理的変更のために複数の領域に手を入れなければならなくなったことはないか。
    それはシステムの抽象化が拙いことが原因かもしれない。

    パイプラインはシステムの抽象化に使える道具の1つ。
    特に、データストリームやバッチ処理を扱う必要があるときにはとても強力な道具。
    パイプラインという言葉がはじめてつかわれたのは1856年ト言われている。
    当時は、液体をある場所から別の場所へ移す一連のパイプを指していた。
    計算機科学でもなにか、つまりデータをある場所から別の場所に移しているので、この用語を拝借した。
    パイプラインはデータを受け取って、何らかの処理を行って、どこかに渡すという一連の作業に過ぎない。
    これらの操作をパイプラインのステージと呼ぶ。

    パイプラインを使うことで、各ステージでの懸念事項を切り分けられる。
    これは多くの利点をもたらす。
    各ステージを独立して修正することができ、ステージ同士の組み合わせ方をステージの修正とは独立して変更できる。
    また各ステージでの処理を上流や下流のステージと平行に行えるし、パイプラインでの細かな処理をファンアウトさせたり流量制限をかけたりできる。

    先に述べたように、ステージはデータを受け取って、変形して、どこかにそれを渡すものでしかない。
    次の関数はパイプラインのステージと考えられるもの。
    ```
        multiply := func(values []int, multiplier int) []int {
            multipliedValues := make([]int, len(values))
            for i, v := range values {
                multipliedValues[i] = v * multiplier
            }
            return multipliedValues
        }
    ```
    この関数は整数のスライスと乗数を受け取って、スライスの中身を繰り返しで受け取りながら乗数をかけていき、結果として新しく作られたスライスを返すつまらない関数。
    それでは別のステージを作ってみよう。

    ```
        add := func(values []int, additive int) []int {
            addedValues := make([]int, len(values))
            for i, v := range values {
                addedValues[i] = v + additive
            }
            return addedValues
        }
    ```
    また退屈な関数。
    この関数はただ新しいスライスを作って各要素に足していくだけ。
    ここで、この2つの関数をただ関数としてではなく、どうやってパイプラインのステージにしていくかと考えているところだろう。
    この2つの関数をつなげてみよう。
    ```
        ints := []int{1,2,3,4}
        for _, v := range add(multiply(ints, 2), 1) {
            fmt.Println(v)
        }
    ```

    結果は次の通り
    ```
        3
        5
        7
        9
    ```

    addとmultiplyをどのようにrange節内で組み合わせたかを見てほしい。
    これらの関数は皆さんが日常的に使う関数だが、ここではパイプラインのステージとしての性質をもつように組み合わせたため、結果パイプラインを形作るように組み合わせることができた。
    ではいったい何がパイプラインのステージの性質なのか・

    - ステージは受け取るものと返すものが同じ型である。
    - ステージは引き回せるように具体化されていなければならない。Goに置いて関数は具体化されているため、この目的にうまく適合している。

    パイプラインのステージは関数プログラミング（高階関数やモナド）と密接に関係していて、モナドのサブセットと考えることもできる。

    addやmultiplyといったステージはパイプラインのステージとしての性質をすべて満たしている。
    両方ともintのスライスを受け取り、intのスライスを返す。
    そしてGoでは具体化された関数があるので、addやmultiplyを引き回せる。
    こうした性質が、先に述べたようなパイプラインのステージの面白い性質を引き起こす。
    つまり、ステージ自体を変更することなく、とても簡単に高水準でステージを組み合わせられるようになる。

    例えば、数を二敗するステージをパイプラインへ追加したい場合には、単純に先のパイプラインを新しいmultiplyステージで包んであげればよい。
    ```
        ints := []int{1,2,3,4}
        for _, v := range multiply(add(multiply(ints,2),1),2) {
            fmt.Println(v)
        }
    ```
    結果は次の通り
    ```
        6
        10
        14
        18
    ```

    新しい関数を書くこともなければ、既存の関数を修正することもなく、またパイプラインから得られた結果を修正することもなく期待した結果が得られたことに着目してほしい。
    おそらくパイプラインの利点を理解し始めたことだろう。
    もちろん、このコードを手続的に書くこともできる。
    ```
        ints := []int{1,2,3,4}
        for _, v := range ints {
            fmt.Println(2*(v*2+1))
        }
    ```

    初めはこのコードのほうがずっと簡潔に見えるが、本書を読み進めていくにしたがって、手続き的なコードはデータのストリームを処理する際にパイプラインが提供してくれるような利点は提供してくれないことに気が付くだろう。

    各ステージがどのようにデータのスライスを受け取り、どのようにデータのスライスを返したか気が付いただろうか。
    これらのステージはいわゆるバッチ処理をしている。
    つまり、個別の値を1つずつ処理していくのではなく、データの塊をいっぺんに処理している。
    パイプラインのステージには他にもストリーム処理を呼ばれる種類がある。
    これはステージが要素を1つずつ受け取って、1つずつ渡すやり方。

    バッチ処理とストリーム処理を比較するとそれぞれに利点と欠点がある。
    元のデータは変更されることなく残り、各ステージでは元データと同じ長さのスライスを新しく作成して計算結果を保存していることに着目してほしい。
    これが意味するところは、プログラム内のある瞬間に必要なメモリのフットプリントはパイプラインの初めに渡したスライスのサイズの倍になるということ。
    それでは先ほどの例をストリーム指向のものに書き換えて、どういう形になるかを見てみよう。

    ```
        multiply := func(value, multiplier int) int {
            return value * multiplier
        }

        add := func(value additive int) int {
            return value + additive
        }

        ints := []int{1, 2, 3, 4}
        for _, v := range ints {
            fmt.Println(multiply(add(multiply(v, 2), 1), 2))
        }
    ```

    これは次のような結果となる。
    ```
        6
        10
        14
        18
    ```
    各ステージは値の受信や送出を個別に行っていて、プログラムでのメモリのフットプリントはパイプラインの入力のサイズまで小さくなる。
    しかし、パイプラインをforループ本体に入れて、パイプラインに値を送り込む重労働をrangeに挿せている。
    この状況は、パイプラインの流し方の再利用を制限するだけでなく、スケールの可能性も制限している。
    また別の問題もある。
    実際には、ループでの繰り返しごとにパイプラインをインスタンス化している。
    関数の呼び出しのコストは低いが、ループの繰り返しごとに3回の関数呼び出しを行っている。
    並行性に関してはどうだろうか。
    パイプラインを利用する利点は個別のステージを並行に処理できる点であると呼べた。

    multiplyやaddといった関数をもう少し拡張してこうした概念を説明することもできるだろうが、先ほどの例はパイプラインの概念を紹介するためのもの。
    Goでのパイプライン処理の構築のためにあるベストプラクティスを勉強していこう。
    Goのチャネルを利用したものから

    