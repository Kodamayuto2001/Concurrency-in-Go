# Goにおける並行処理の構成要素

- ゴルーチン（goroutine）
    すべてのGoのプログラムには最低1つのゴルーチンがある。
    メインゴルーチン
    これは、プロセスが開始する際に自動的に生成され起動される。
    単純に言えば、ゴルーチンは他のコードに対し並行に実行している関数のこと（注意：必ずしも並列ではない）
    ゴルーチンはgoキーワードを関数呼び出しの前に置くことで簡単に起動できる。
    無名関数でも動作する。（goキーワードを使うには無名関数を即値で呼び出さなければいけない）

    ゴルーチンは（他の言語にも似た並行処理のプリミティブは存在するが）Go特有のもの。
    ゴルーチンはOSスレッドではなく、また必ずしもグリーンスレッド（言語のランタイムにより管理されるスレッド）ではない。
    ゴルーチンはコルーチン（coroutine）として知られる高水準の抽象化。
    コルーチンは単に「プリエンプティブでない」並行処理のサブルーチン（Goでは関数、クロージャー、メソッドに相応）
    つまり割り込みをされることがないということ
    代わりに、コールチンには一時停止や再エントリーを許す複数のポイントがある。

    ```
        プリエンプティブとノンプリエンプティブは、ともにマルチタスクOS上で実行されるプログラムを切り替えるときの方式
        プリエンプティブ
            OSがCPUやシステム資源を管理し、CPU使用時間や優先度などによりタスクを実行状態や実行可能状態に切り替える方式。
        ノンプリエンプティブ
            実行したプロセスの切り替えをプログラム自身に任せる方式で、プログラムが自発的にCPUを開放した時間で他のタスクを実行する。
            OSがCPUを管理しないので、1つのプログラムを実行中は、他のプログラムの実行は制限される。
    ```

    ゴルーチンが独特なのは、ゴルーチンがGoのランタイムと密結合していること
    ゴルーチンは、一時停止や再エントリーのポイントを定義していない。
    Goのランタイムはゴルーチンの実行時のふるまいを観察し、ゴルーチンがブロックしたら自動的に一時停止し、ブロックが解放されたら再開する。
    これによってある意味ゴルーチンをプリエンプティブにしているが、ゴルーチンがブロックしたときにしか割り込まない。
    このようにランタイムとゴルーチンのロジックには美しい関係性がある。
    以上のことからゴルーチンは特殊なコールチンと考えられる。
    
    コルーチン、また結果としてゴルーチンは、暗黙的には並行処理の構成要素ですが、並行性というのはコールチンの性質ではない。
    並行である場合には、何かが複数のコルーチンが同時管理して、それぞれに実行の機会を与えなければならない。さもなければ、コルーチンが並行になることはない。
    コールチンが暗黙的に並列であるということを示唆するわけではない。
    複数のコルーチンが逐次実行をして（CPUのコア数以上に）並行処理をしているように見せることは確実に可能。
    そしてGoでは常にそれが起こっている。

    Goがゴルーチンをホストする機構は、いわゆるM:Nスケジューラーを呼ばれる実装になっている。
    これはM個のグリーンスレッドをN個のOSスレッドに対応させるもの。
    ゴルーチンはグリーンスレッドにスケジュールされる。
    グリーンスレッドの数よりも多い数のゴルーチンがある場合には、スケジューラーはゴルーチンを利用可能なグリーンスレッドに割り振って、これらのゴルーチンがブロックした場合には他のゴルーチンを実行するようにしている。

    Goはfork-joinモデルを呼ばれる並行処理のモデルに従っている。
    分岐（fork）という用語は、プログラムの任意の場所で、プログラムが子の処理を分岐させて、親と平行に実行させることを指している。
    合流（join）という用語は、分岐した時点から先でこれらの並行処理の分岐が再び合流することを指す。

    ```
        sayHello := func() {
            fmt.Println("hello")
        }

        go sayHello()
    ```

    sayHello関数は自身のゴルーチン上で実行される。かたや、プログラムの続きの部分は引き続き実行される。
    この例には、合流ポイントがない。
    sayHelloを実行しているゴルーチンは単純に将来の不確定なタイミングで終了する。
    プログラムの残りの部分はすでに引き続き実行されている。
    しかしながら、この例には1つ問題がある。
    sayHello関数が実行されたかどうかは不確定。
    ゴルーチンは生成されて、Goのランタイムにスケジュールされるが、もしかするとメインゴルーチンが終了するまでに実行する機会を得られないかもしれない。
    事実、（サンプルを）簡単にするためmain関数の残りの部分を省略したので、この小さなサンプルを実行すると、プログラムがsayHelloの呼び出しをホストしているゴルーチンが起動する前に終了してしまうことがほぼ確実
    ゴルーチンを作った後にtime.Sleepを書くこともできるが、合流ポイントは作成せず、ただ競合状態を作っているだけ。
    プログラムの終了の前にゴルーチンが起動する確率を上げることはできるが、それを保証するものではない。
    合流ポイントはプログラムの正当性を保証し競合状態を取り除くものである。

    合流ポイントを作成するために、メインゴルーチンとsayHelloのゴルーチンを同期しなければならない。
    これはいくつもの方法で実現可能、sync.WaitGroupを使って実装することができる。
    ```
        var wg sync.WaitGroup
        sayHello := func() {
            defer wg.Done()
            fmt.Println("hello")
        }
        wg.Add(1)
        go sayHello()
        wg.Wait()
    ```
    
    この例は決定的にsayHello関数をホストしているゴルーチンが終了するまで、メインゴルーチンをブロックする。
    手早くゴルーチンを生成するためにたくさんの無名関数を使ってきた。
    クロージャは無名関数が作成されたときレキシカルスコープを閉じ込めて、そこに変数を取り込む。
    ゴルーチンの中でクロージャを実行すると、クロージャーはこれらの変数のコピーに対して操作するのか
    それとも元の変数の参照に対してだろうか
    ```
        var wg sync.WaitGroup
        salutation := "hello"
        wg.Add(1)
        go func() {
            defer wg.Done()
            salutation = "welcome"
        } ()
        wg.Wait()
        fmt.Println(salutation)
    ```
    出力は、「welcome」
    ゴルーチンはそれが作られたアドレス空間と同じ空間で実行されることが分かった。
    そしてそれゆえにプログラムが"welcome"を表示している。

    - スコープ
        スコープとは、プログラム中で変数名などのシンボルが参照可能な有効範囲のこと。
        ```
            var hoge = "ほげ";      //  グローバルスコープ（グローバル変数）

            function a() {
                var x = 10;         //  ローカル変数
                console.log(x);
                console.log(hoge);
            }

            function b() {
                var hoge = "hoge";  //  ローカル変数
                console.log(hoge);
            }

            console.log(hoge);      //  ほげ
            console.log(x);         //  error
        ```
    - レキシカルスコープ
        ローカル変数の有効範囲は関数の定義時に決まるものなのか、他の場所で呼び出した時に決まるのか？
        レキシカルスコープは関数を定義した時点でスコープが決まる。
        ```
            var x = 10;
            function A() {
                console.log(x);         //  x = 10
            }

            function B() {
                var x = 1000;           //  ここでも定義されている。
                A();                    //  x = ?
            }

            A()                         //  10
            B()                         //  10
        ```

    - ダイナミックスコープ
        ```
            var x = 10;
            function A() {
                console.log(x);         //  x = 10
            }

            function B() {
                var x = 1000;           //  ここでも定義されている。
                A();                    //  x = ?
            }

            A()                         //  10
            B()                         //  1000（10ではなくなった）
        ```

    - クロージャ
        クロージャは「関数」と「その関数が作られた環境」という2つのものが一体となった特殊なオブジェクト
        この「環境」というのは、クロージャが作られた時点でスコープ内部にあったあらゆる変数や関数・オブジェクトなどによって構成される。
    
        ```
        function fnA() {
            var hoge = "ほげ";
            console.log(hoge);

            function fnB() {
                alert(hoge);
            }

            return fnB;
        }

        var myFunc = fnA();

        myFunc();
        //  myFunc();
        ```

        実行結果
            1. コンソールに"ほげ"という出力がされる
            2. アラートで"ほげ"とメッセージが出現する

        もう一度myFunc();を呼び出してあげると、コンソールの出力はなく、アラートで"ほげ"とでてくるのみ
        ローカル変数hogeは、関数fnA内部のローカル変数であるので、関数fnAの実行中以外では参照することはできないはずです。
        「JavaScriptのローカル変数は、関数が実行されるたびに作成され破棄される」「関数内部のローカル変数は、その関数が実行されている間だけ存在する」

        では、上記の例で関数fnAを実行しているのはどこかというと、変数myFuncが定義されたとき
        つまり、この瞬間でのみ、ローカル変数hogeを参照することができる。
        関数fnAの中身を見ると「return fnB;」とあるので、グローバル変数myFuncに代入されるのは、関数fnBということになる。
        
        「var myFunc = fnA();」の部分を置き換えてみると
        ```
        var myFunc = function fnB() {
            alert(hoge);
        }
        ```

        つまり、「myFunc()」=「alert(hoge);」となる。

        関数fnAが実行されていないのに、関数fnA内部のローカル変数hogeを参照できている
        「クロージャは「関数」と「その関数が作られた環境」という2つのものが一体となった特殊なオブジェクト」

        関数がクロージャになる条件
        「関数は定義時のコンテキストとは異なるコンテキスト上に持ち出されるとクロージャになる」

        関数fnAのような親関数の実行によって、ローカル関数が外部へと持ち出されるときにクロージャが生成されることが分かった。
        このような、クロージャを生成できる親関数のことを「エンクロージャー」と呼ぶらしい


    ```
        var wg sync.WaitGroup
        for _, salutation := range []string{"hello", "greetings", "good day"} {
            wg.Add(1)
            go func() {
                defer wg.Done()
                fmt.Println(salutation) //  1
            }()
        }
        wg.Wait()
    ```

    1. ここで文字列スライスをrangeしたときに作られたループ変数のsalutationを参照している。

    結果
    ```
        good day
        good day
        good day
    ```

    この例では、ゴルーチンは文字列型の反復変数salutationを囲むクロージャーを実行している。
    ループが繰り返すごとにsalutationには次のスライスリテラル内の文字列値が代入される。
    ゴルーチンは未来の任意のタイミングにスケジュールされているので、ゴルーチンの中で土の値が表示されるかは不確定。
    ゴルーチンが開始する前にループが終了してしまうことがほとんど
    つまり、salutation変数はスコープ買いになってしまう。
    ゴルーチンはスコープ買いのものを参照し続けることができるのだろうか
    ガベージコレクションされる可能性があるメモリをアクセスして今うのか

    これはGoのメモリ管理に関する面白いこぼれ話
    Goのランタイムは気が利いているので変数salutationへの参照がまだ保持されているかを知っていて、ゴルーチンがそのメモリにアクセスし続けられるようにメモリをヒープに移す。
    通常のマシンでは、どんなゴルーチンでも開始する前にループが終了してしまう。なのでsalutationは文字列のスライスの最後の値であるgood dayへの参照を保持したままヒープに移される。
    それゆえ、私のマシンでは通常good dayが3回表示される。
    個のループを想定したように正しく書くには、salutationのコピーをクロージャーに渡して、ゴルーチンが実行されるようになるまでにループの各繰り返しから渡されたデータを操作できるようにする。
    ```
        var wg sync.WaitGroup
        for _, salutation := range []string{"hello", "greetings", "good day"} {
            wg.Add(1)
            go func(salutation string) {    //  1
                defer wg.Done()
                fmt.Println(salutation)
            }(salutation)                   //  2
        }
        wg.Wait()
    ```

    1. ここで、普通の関数と同じように引数を宣言する。元のsalutation変数をシャドーイングして何を渡すべきかを明確にする。
    2. ここで現在の繰り返しの変数をクロージャーに渡す。文字列の構造体のコピーが行われ、それによってゴルーチンが実行されたときに、適切な文字列を参照するようにする。

    結果
    ```
        good day
        hello
        greetings
    ```
    このれいは想定したとおりに動作している。
    そしてわずかながらより詳細に記述されている。
    ゴルーチンはお互いに同じアドレス空間を操作していて、単純に関数をホストしているため、ゴルーチンを使うことは並行でないコードを書くことの自然な延長になっている。
    Goのコンパイラはうまい具合に変数をメモリに割り当ててくれて、ゴルーチンが解放されたメモリに間違ってアクセスしてしまわないようにしている。これによって開発者がメモリ管理ではなく問題空間に集中できる。
    しかしなんでも勝手にできるわけではない。
    複数のゴルーチンが同じアドレス空間に対して操作するので、依然として同期に関しては気にかけねばならない。先に説明したように、ゴルーチンがアクセスする共有メモリへのアクセスを同期する、またはCSPのプリミティブを使って通信によってメモリを共有するか、いずれかの方法を選択できる。
    ゴルーチンのほかの利点は、ゴルーチンが信じられないほど軽量であること。
    新しく生成されたゴルーチンには数キロバイトのメモリが与えられる。これでほぼ問題ない。もしメモリが足りない場合は、ランタイムがメモリを自動的に増加（あるいは現象）させてスタックを保持できるようにし、多くのゴルーチンが適切な量のメモリの中で生存できるようにしている。CPUのオーバーヘッドとして関数呼び出しごとに平均でコストが低い操作を3つ程度行う。実際に、何百男全ものゴルーチンが同じアドレス空間に生成されている。ゴルーチンが単位スレッドだったら、もっとずっと少ない数でシステムリソースが枯渇してしまうだろう


    ```
        memConsumed := func() uint64 {
            runtime.GC()
            var s runtime.MemStats
            runtime.ReadMemStats(&s)
            return s.Sys
        }

        var c <-chan interface{}
        var wg sync.WaitGroup
        noop := func() { wg.Done(); <-c }       //  1

        const numGoroutines = 1e4               //  2
        wg.Add(numGoroutines)
        before := memConsumed()                 //  3
        for i := numGoroutines; i > 0; i-- {
            go noop()
        }
        wg.Wait()
        after := memConsumed()                  //  4
        fmt.Printf("%.3fkb\n", float64(after-before)/numGoroutines/1000)
    ```

    1. 計算のためにたくさんのゴルーチンをメモリに置いておきたいので、絶対に終了しないゴルーチンが必要。ただ、個のゴルーチンはプロセスが終わるまで終了しない。
    2. ここで生成するゴルーチンの数を定義している。台数の法則を使って漸近的にゴルーチンの数を増やしていく。
    3. ここでゴルーチン生成前のメモリ消費量を計算する。
    4. ここでゴルーチン生成後のメモリ消費量を計算する。
    
    コンテキストスイッチ
    コンテキストスイッチとは並行プロセスをホストしているものが別の並行プロセスに切り替えるために状態を保存しなければならないときにおこるもの。
    並行プロセスが過剰にある場合、CPU時間をすべてコンテキストスイッチに費やしてしまい、本来行いたい処理が一切行われないということが起こりえる。オペレーティングシステムの層でいえば、スレッドのコンテキストスイッチは非常にコストが高くなる。OSスレッドはレジスタの値、参照テーブル、メモリマップといったものを保存して、今必要なスレッドに切り替えなければならない。そして、そういった情報を新しいスレッドに読み込ませなければならない。
    ソフトウェア内に置けるコンテキストスイッチのコストは、これに比較するとずっとずっと小さくなる。ソフトウェアで定義したスケジューラでは、ランタイムは何をどのように、いつ永続化すべきかに関して、より多くの選択肢がある。

    ```
    func BenchmarkContextSwitch(b *testing.B) {
        var wg sync.WaitGroup
        begin := make(chan struct{})
        c := make(chan struct{})

        var token struct{}
        sender := func() {
            defer wg.Done()
            <-begin         //  1
            for i := 0; i < b.N; i++ {
                c <- token  //  2
            }
        }
        receiver := func() {
            defer wg.Done()
            <-begin         //  1
            for i := 0; i < b.N; i++ {
                <-c         //  3
            }
        }

        wg.Add(2)
        go sender()
        go receiver()
        b.StartTimer()      //  4
        close(begin)        //  5
        wg.Wait()
    }
    ```

    1. 開始(begin)といわれるまで待機する。コンテキストスイッチの計測にゴルーチンの設定と起動の時間を入れたくなかったから。
    2. 受信側のゴルーチンにメッセージを送信している。struct{}はから構造体と呼ばれるもので、メモリを消費しない。これによって、メッセージを創出する時間だけを計測できる。
    3. メッセージを受信するが、何もしない。
    4. タイマーを起動する。
    5. 2つのゴルーチンに開始を伝える。

- syncパッケージ
    syncパッケージには低水準のメモリアクセス同期に便利な並行処理のプリミティブが入っている。
    Goに特有の点といえば、Goではメモリアクセス同期のプリミティブの上に新しい並行処理のプリミティブを作り、新しい道具を用意したところ。
    これらの操作は、たいていはstructのような小さなスコープ
    メモリアクセス同期がいつ適切かを決めるのは利用者次第。
    syncパッケージにあるプリミティブ

- WaitGroup
    WaitGroupはひとまとまりの並行処理があったとき、その結果を気にしない、若しくは他に結果を収集する手段がある場合に、それらの処理の完了を待つ手段として非常に有効。
    どちらの前提も当てはまらない場合には、かわりにselect文を使うことをお勧めする。
    WaitGroupは非常に便利
    ```
        var wg sync.WaitGroup

        wg.Add(1)               //  1
        go func() {
            defer wg.Done()     //  2
            fmt.Println("1st goroutine sleeping...")
            time.Sleep(1)
        }()

        wg.Add(1)               //  1
        go func() {
            defer wg.Done()     //  2
            fmt.Println("2nd goroutine sleeping...")
            time.Sleep(2)
        }()

        wg.Wait()               //  3
        fmt.Println("All goroutines complete.")
    ```

    1. Addを引数に1を渡して呼び出し、1つのゴルーチンが起動したことを表している。
    2. Doneをdeferキーワードを使って呼び出して、ゴルーチンのクロージャが終了する前にWaitGroupに終了することを確実に伝えるようにしている。
    3. Waitを呼び出している。すべてのゴルーチンが終了したと伝えるまでメインゴルーチンをブロックする。

    WaitGroupを並行処理で安全なカウンターと考えることができる。
    Addを呼び出すと引数に渡された整数だけカウンターを増やし、Doneを呼び出すとカウンターを1つ減らす。Waitを呼び出すとカウンターがゼロになるまでブロックする。
    Addの呼び出しは監視対象のゴルーチンの外で行われている。
    こうしないと競合状態を引き起こしてしまう。
    ゴルーチンがスケジュールされるタイミングに関しては何の保証もないから。
    ゴルーチンが開始する前にWaitの呼び出しが起きてしまう可能性がある。ゴルーチンのクロージャの中でAddが呼び出されている場合、Addの呼び出しが実行されないためWaitの呼び出しはブロックせずに実行されてしまうかもしれない。

    Addの呼び出しはできる限り監視対象のゴルーチンの直前に書くというのが慣習。しかし、時に関連するゴルーチンの呼び出しを一度に監視するために、Addの呼び出しが行われているのを見ることもあるだろう。
    ```
        hello := func(wg *sync.WaitGroup, id int) {
            defer wg.Done()
            fmt.Printf("Hello from %v\n", id)
        }

        const numGreeters = 5
        var wg sync.WaitGroup
        wg.Add(numGreeters)
        for i := 0; i < numGreeters; i++ {
            go hello(&wg, i+1)
        }
        wg.Wait()
    ```

    - MutexとRWMutex
        メモリアクセス同期を使って並行処理を扱う言語に慣れている人であれば、Mutexと聞いてすぐにわかるだろう。
        Mutexは「相互排他」を表す英語の mutual exclusionの略で、プログラム内のクリティカルセクションを保護する方法の一つ。クリティカルせくりょんは、プログラムが共有リソースに対する排他的アクセスを必要とする場所のこと。Mutexは並行処理で安全な方法でこれらの共有リソースに対する排他的アクセスを提供している。
        「Goらしさ」の発言を借りてくれば、チャネルは通信によってメモリを共有し、Mutexは開発者が守らなければならないメモリに対する同期アクセスの観衆を作ることでメモリを共有している。ミューテックスを使ってこのメモリに対する慎重なアクセスを自分で調整する責任がある。ここで共通の変数をそれぞれ増加と減少させようとしている2つのゴルーチンの例を見る。この例ではMutexを使って変数へのアクセスを同期している。

        ```
            var count int
            var lock sync.Mutex

            increment := func() {
                lock.Lock()         //  1
                defer lock.Unlock() //  2
                count++
                fmt.Printf("Incrementing: %d\n", count)
            }

            decrement := func() {
                lock.Lock()         //  1
                defer lock.Unlock() //  2
                count--
                fmt.Printf("Decrementing: %d\n", count)
            }

            //  インクリメント
            var arithmetic sync.WaitGroup
            for i := 0; i <= 5; i++ {
                arithmetic.Add(1)   
                go func() {
                    defer arithmetic.Done()
                    increment()
                }()
            }

            //  デクリメント
            for i := 0; i <= 5; i++ {
                arithmetic.Add(1)
                go func() {
                    defer arithmetic.Done()
                    decrement()
                }()
            }

            arithmetic.Wait()

            fmt.Println("Arithmetic complete.")
        ```

        1. lockというMutexインスタンスで保護されたクリティカルセクション（この場合count変数の占有）を要求している。
        2. lockが保護しているクリティカルセクションでの処理が終了したことを示している。

        Unlockへの呼び出しが常にdeferの中にある。
        これはMutexを使うときによく使われるイディオム
        これによって、たとえpanicになったとしても確実に呼び出せる。
        呼び出しに失敗してしまうとデッドロックが発生してしまう。
        クリティカルセクションはプログラムのボトルネックを反映しているので、そう名付けられた
        クリティカルセクションへの出入りはいくらかコストが高いので、一般的にはクリティカルセクションで消費される時間を極力短くしようとする。
        そうするための戦略の1つはクリティカルセクションの断面積を減らすこと。
        複数の並行処理のプロセスで共有する必要があるメモリがあるかもしれない。
        しかし、おそらくそれらのプロセスのうちの全てがメモリの読み込みと書き込みの両方を必要とするわけではない。もしそうであれば、別種類のミューテックスであるsync.RWMutexが使える。
        sync.RWMutexは概念的には、Mutexと同じもの。これもメモリへのアクセスを保護する。しかしながらRWMutexはメモリに対する管理をMutexより多く提供している。
        メモリに対する読み込みのロックを要求した場合、ロックが書き込みで保持されていなければ、アクセスを得ることができる。
        つまり、書き込みのロックをしているものがいなければ、任意の数の読み込みのロックがとれるというわけ。

        ```
            producer := func(wg *sync.WaitGroup, l sync.Locker) {   //  1
                defer wg.Done()
                for i := 5; i > 0; i-- {
                    l.Lock()
                    l.Unlock()
                    time.Sleep(1)   //  2
                }
            }

            observer := func(wg *sync.WaitGroup, l sync.Locker) {
                defer wg.Done()
                l.Lock()
                defer l.Unlock()
            }

            test := func(count int, mutex, rwMutex sync.Locker) time.Duration {
                var wg sync.WaitGroup
                wg.Add(count+1)
                beginTestTime := time.Now()
                go producer(&wg, mutex)
                for i := count; i > 0; i-- {
                    go observer(&wg, rwMutex)
                }

                wg.Wait()
                return time.Since(beginTestTime)
            }

            tw := tabwriter.NewWriter(os.Stdout, 0, 1, 2, ' ', 0)
            defer tw.Flush()

            var m sync.RWMutex
            fmt.Fprintf(tw, "Readers\tRWMutex\tMutex\n")
            for i := 0; i < 20; i++ {
                count := int(math.Pow(2, float64(i)))
                fmt.Fprintf(
                    tw,
                    "%d\t%v\t%v\n",
                    count,
                    test(count, &m, m.RLocker()),
                    test(count, &m, &m),
                )
            }
        ```

        1. producer関数の2番目の引数はsync.Locker型。このインターフェースにはLockとUnlockという2つのメソッドがある。このインターフェースはMutex型とRWMutex型を満たす。
        2. 生産者を1ナノ秒スリープさせて、observerゴルーチンよりも非活発にする。

        論理的に意味があると思うときはMutexではなく、RWMutexを使うことをお勧め


    - Cond
        Cond型のコードに書いてあるコメントはその目的を上手に記述している。
        ```
            ゴルーチンが待機したりイベントの発生を知らせるためのランデブーポイント
        ```

        この定義で「イベント」は2つ以上のゴルーチン間で、それが発生したということ以外の情報がない任意のシグナルを指す。
        ゴルーチン上で処理を続ける前にこうした信号を受け取りたいということは非常に多くある。
        こうした要望をCond型を使わずに実現する方法として、無限ループを使う方法がある。
        ```
            for !conditionTrue() {

            }
        ```

        しかし、この実装ではCPUのコアを占有してしまうので、修正のためにtime.Sleepを入れる。
        ```
            for !conditionTrue() {
                time.Sleep(1*time.Millisecond)
            }
        ```

        多少良くなったが、まだ不十分。スリープさせる長さを気にしなければいけない。長すぎると人為的にパフォーマンスを落としてしまうし、短すぎるとCPU時間を無駄に消費してしまう。ゴルーチンをシグナルが来てその中身を確認するまで効率的にスリープさせられれば、そのほうが良い。これがCond型が行ってくれること。
        ```
            c := sync.NewCond(&sync.Mutex{})    //  1
            c.L.Lock()                          //  2
            for !conditionTrue() {
                c.Wait()                        //  3
            }
            c.L.Unlock()                        //  4
        ```

        1. 新しいCondのインスタンスを作る。NewCond関数はsync.Lockerインスタンスを満たす型を引数にとる。これによって、Cond型が他のゴルーチンを並行処理で安全な方法で協調できるようになる。
        2. この条件でLockerをロックする。これはWaitへの呼び出しがループに入るときに自動的にUnlockを呼び出すため必要。
        3. 条件が発生したかどうかが通知されるのを待つ。これはブロックする呼び出しで、ゴルーチンは一時停止する。
        4. この条件でLockerのロックを解除する。この記述はWaitの呼び出しが終わると、この条件でLockを呼び出すので、必要。

        この方法は、スリープを自分で設定するよりずっと効率的。Waitの呼び出しはただブロックするだけではなく、現在のゴルーチンを一時停止する。注手他のゴルーチンが同じOSスレッド乗で動作できるようにする。ほかにもWaitを呼び出すと、Condの引数であるLockerのUnlockが呼ばれる。そして、Waitを抜けると、今度は同じLockerのLockが呼ばれる。Condを使うには少し慣れが必要。今見たように、Condのメソッドには効率のための隠れた副作用があるから。コードの見た目上、Condは条件が起きるのを待っている間ロックをずっと保持しているようにみえるが、実際はそうではない。

        ※コンテキストスイッチのコストが低いという説明をすでにしましたが、Goのランタイムは、生成されたゴルーチンのうち、ブロックされているゴルーチンへのコンテキストスイッチを行わないため、Condによるシステム全体のスループットへの影響はありません。
        これはこれまで説明してきたMutexやWaitGroupでも同様

        ```
            c := sync.NewCond(&sync.Mutex{})        //  1
            queue := make([]interface{}, 0, 10)     //  2

            removeFromQueue := func(delay time.Duration) {
                time.Sleep(delay)
                c.L.Lock()                          //  8
                queue = queue[1:]                   //  9
                fmt.Println("Removed from queue")   
                c.L.Unlock()                        //  10
                c.Signal()                          //  11
            }

            for i := 0; i < 10; i++ {
                c.L.Lock()                          //  3
                for len(queue) == 2 {               //  4
                    c.Wait()                        //  5
                }
                fmt.Println("Addting to queue")
                queue = append(queue, struct{}{})
                go removeFromQueue(1*time.Second)   //  6
                c.L.Unlock()                        //  7
            }
        ```
        
        1. まず標準のsync.MutexをLockerとして使って条件を作成する。
        2. 次に、長さ0のスライスを作成する。最終的に10足すとわかっているので、キャパシティーを10に設定する。
        3. 条件であるLockerのLockメソッドを呼び出してクリティカルセクションに入る。
        4. ループ内でキューの長さを確認する。これは重要である。なぜなら条件上のシグナルは必ずしも同じ待っている事象が起きたとこを意味していないから、何かが起きただけ。
        5. Waitを呼び出す。これによって条件のシグナルが創出されるまでメインゴルーチンを一時停止する。
        6. 1秒後に要素をキューから取り出す新しいゴルーチンを生成する。
        7. 要素を無事キューに追加出来たので条件のクリティカルセクションを抜ける。
        8. 再度条件のクリティカルセクションに入って、条件に合った形でデータを修正する。
        9. スライスと先頭をスライスの2番目の要素を指すように変えることでキューから取り出したことにする。
        10. 無事に要素をキューから取り出したので条件のクリティカルセクションを抜ける。
        11. 条件を待っているゴルーチンに何かが起きたとこを知らせる。

        新たに1つのアイテムをキューに追加する前に少なくとも1つの要素がキューから取り出されるのを待つ。
        この例では新しいメソッドSignalを紹介している。これはCond型でWaitでブロックされたゴルーチンに通知をするために提供している2つのメソッドのうち1つで、条件が発動したことを知らせる。もう1つのメソッドはBroadcast。内部的には、ランタイムがシグナルを待機しているゴルーチンのFIFOのリストを管理している。Signalはシグナルを一番長く待っているゴルーチンを見つけて、そのゴルーチンにシグナルを伝えるが、一方でBroadcastはシグナルを待っているすべてのゴルーチンにシグナルを伝える。Broadcastは複数のゴルーチンと同時に通信する方法を提供しているので、2つのメソッドのうちではおそらくそちらのほうが興味深い。Signalはチャネルを使って簡単に再現できるが、Broadcastを繰り返し呼び出した時の動作をチャネルで再現するのは難しいだろう。加えて、Cond型はチャネルを使うより性能が高くなる。
        Broadcastを使う場面に関する感覚を得るために、ボタンがあるGUIアプリを想像してみる。
        ボタンがクリックされたときに実行される関数を、任意の数だけ登録したいとする。Condはこの用途に最適。なぜならBroadcastメソッドを使って、登録したハンドラーのすべてに通知ができるから。

        ```
            type Button struct {        //  1
                Clicked *sync.Cond
            }
            button := Button{ Clicked: sync.NewCond(&sync.Mutex{})}

            subscribe := func(c *sync.Cond, fn func()) {    //  2
                var goroutineRunning sync.WaitGroup
                goroutineRunning.Add(1)
                go func() {
                    goroutineRunning.Done()
                    c.L.Lock()
                    defer c.L.Unlock()
                    c.Wait()
                    fn()
                }()
                goroutineRunning.Wait()
            }

            var clickRegistered sync.WaitGroup          //  3
            clickRegistered.Add(3)                      
            subscribe(button.Clicked, func() {          //  4
                fmt.Println("Maximizing window.")
                clickRegistered.Done()
            })
            subscribe(button.Clicked, func() {          //  5
                fmt.Println("Displaying annoying dialog box!")
                clickRegistered.Done()
            })
            subscribe(button.Clicked, func() {          //  6
                fmt.Println("Mouse clicked.")
                clickRegistered.Done()
            })

            button.Clicked.Broadcast()
            clickRegistered.Wait()                      //  7
        ```

        1. Clickedという条件を含んでいるButton型を定義する。
        2. 条件に応じて送られてくるシグナルを扱う関数を登録するための便利な関数を定義する。各ハンドラーはそれぞれゴルーチン上で動作する。そしてsubscribeはゴルーチンが実行されていると確認できるまで終了しない。
        3. WaitGroupを作る。これはプログラムがstdoutへ書き込む前に終了してしまわないようにするためだけのもの
        4. ボタンがクリックされたときに、ボタンがあるウィンドウを最大化するのをシミュレートしたハンドラーを登録する。
        5. マウスがクリックされたときにダイアログボックスを表示するのをシミュレートしたハンドラーを登録する。
        6. 次に、ユーザーがアプリケーションのボタンをクリックした状態からマウスのボタンを離した状態をシミュレートする。
        7. マウスのボタンが話されたときのハンドラーを設定する。こちらはClickedという状態(Cond)に対応するBroadcastを呼び出して、全てのハンドラーにマウスのボタンがクリックしたということを知らせる。（より堅実な実装では最初にボタンが押下されたかを確認すればよい）

        Clicked問う状態(Cond)のBroadcastを一度呼び出しただけで、3つのハンドラすべてが実行されている。clickRegisteredというWaitGroupがなければ、button.Clicked.Broadcast()を何度も呼び出して、3つのハンドラーを何度も呼び出せただろう。これはチャネルでは容易に実装出来ないし、それゆえにCond型を利用する主な理由の1つになっている。
        syncパッケージ内の他のものと同様に、Condは狭い範囲に制限したり、広い範囲に公開する場合もそれをカプセル化した型に入れて利用するのが最適

    - Once
        ```
            var count int

            increment := func() {
                count++
            }

            var once sync.Once

            var increments sync.WaitGroup
            increments.Add(100)
            for i := 0; i < 100; i++ {
                go func() {
                    defer increments.Done()
                    once.Do(increment)
                }()
            }

            increments.Wait()
            fmt.Printf("Count is %d\n", count)
        ```

        sync.Onceがある。
        incrementの呼び出しをonceのDoメソッドでラップしている。
        事実、このコードは次の出力をする。
        ```
            Count is 1
        ```
        名前が示しているようにsync.Onceは内部的にsyncの何らかのプリミティブを使って、Doに渡された関数が（たとえ異なるゴルーチンで呼ばれたとしても）一度しか実行されないようにする型である。実際、これがsync.OnceのDoメソッドでincrementの呼び出しをラップした理由
        関数を確実に一度だけ呼び出すことができる機能を標準パッケージ内に入れるのは奇妙に思うかもしれないが、このパターンの需要は思って以上に多い。

        sync.Onceを使う上で気を付けることがいくつかある。
        ```
            var count int
            increment := func() { count++ }
            decrement := func() { count-- }

            var once sync.Once
            once.Do(increment)
            once.Do(decrement)

            fmt.Printf("Count: %d\n", count)
        ```
        次のような結果になる。
        ```
            Count: 1
        ```
        0ではなく1が出力された。そうなった理由は、sync.OnceはDoが呼び出された回数だけを数えていて、Doに渡された一意な関数が呼び出された回数を数えているわけではないから。このように、sync.Onceのコピーは呼び出そうとしている関数と強く紐づいている。再度、syncパッケージ内の型を使うときは狭い範囲が最適であるということを確認する。
        sync.Onceを使う問いはいつでも小さなレキシカルスコープ、つまり小さな関数あるいは型、で囲むことを定形にすることをお勧めする。

        ```
            var onceA, onceB, sync.Once
            var initB func()
            initA := func() { onceB.Do(initB) }
            initB = func() { onceA.Do(initA) }  //  1
            onceA.Do(initA)                     //  2
        ```
        1 この関数呼び出しは 2の関数呼び出しが値を返すまで怒らない。
        このプログラムはデッドロックする。
        なぜなら1でのDoの呼び出しは、2のDoが終了するまで進まないから。
        古典的なデッドロックの例。sync.Onceを使って、複数回の初期化をしていないように見えるので、子の挙動が直感に反すると感じる人も多いと思う。しかしsync.Onceが保証しているのは、関数が一度しか呼ばれないことだけ。プログラム内でこう言ったことをしてデッドロックをしてしまい、プログラムに不具合を生じさせてしまうことがある。この例の場合は、循環参照。

    - Pool
        Poolはオブジェクトプールパターンを並行処理で安全な形で実装したもの
        しかしながら、Poolはsyncパッケージに属しているので、その面白い点についてここで簡単に説明する。
        大まかに言えば、オブジェクトプールパターンは、使うものを決まった数だけ、言い換えればプールを作る方法。
        この方法はコストが高いもの（例：データベース接続）を作るときに数を制限して、決まった数しか作られないようにしつつ、予測できない数の操作がこれらにアクセスをリクエストできるようにするときによく使われる。Goのsync.Poolの場合、このデータ型は複数のゴルーチンから安全に使うことができる。
        Poolの主なインターフェースはGetメソッド。Getが呼び出されたときには、まずプール内に使用可能なインスタンスがあるか確認し、あれば呼び出し元にそれを返す。もしなければ、Newメンバー変数を呼び出し、新しいインスタンスを作成する。作業が終わったら、呼び出し元はPutを読んで、使っていたインすんタンスをプールに戻して、他のプロセスが使えるようにする。次のコードはPoolの簡単な使用例。
        ```
            myPool := &sync.Pool {
                New: func() interface{} {
                    fmt.Println("Creating new instance.")
                    return struct{}{}
                }
            }

            myPool.Get()                //  1
            instance := myPool.Get()    //  1
            myPool.Put(instance)        //  2
            myPool.Get()                //  3
        ```
        1. プールのGetを呼び出す。この2つの呼び出しによって、プールに定義されているNew関数を起動する。なぜならインスタンスがまだ初期化されていないから。
        2. 先にプールから取得したインスタンスをプールに戻す。これで利用できるインスタンスの数を1に増やす。
        3. 子の呼び出しが実行されたときは、先に生成されてプールに戻されたインスタンスを再利用する。New関数は呼び出されない

        ```
            Creating new intsance.
            Creating new instance.
        ```

        なぜオブジェクトが必要な時にただインスタンス化するのではなく、プールを使うのだろうか？Goにはガベージコレクターがあるので、インスタンス化されたオブジェクトは自動的に消去される。ポイントは何か？
        ```
            var numCalcsCreated int
            calcPool := &sync.Pool {
                New: func() interface{} {
                    numCalcsCreated += 1
                    mem := make([]byte, 1024)
                    return &mem                     //  1
                },
            }

            //  プールに4KB確保する
            calcPool.Put(calcPool.New())
            calcPool.Put(calcPool.New())
            calcPool.Put(calcPool.New())
            calcPool.Put(calcPool.New())

            const numWorkers = 1024*1024
            var wg sync.WaitGroup
            wg.Add(numWorkers)
            for i := numWorkers; i > 0; i-- {
                go func() {
                    defer wg.Done()

                    mem := calcPool.Get().(*[]byte) //  2
                    defer calcPool.Put(mem)

                    //  何か面白いことを行う
                    //  ただしメモリに対して素早い処理が行われること。
                }()
            }

            wg.Wait()
            fmt.Printf("%d calculator were created.", numCalcsCreated)
        ```
        1. バイトのスライスのアドレスを保存している。
        2. バイトのスライスのポインタであると型アサーションしている。

        この結果は次のようになる。
        ```
        8 calculators were created.
        ```
        
        この例をsync.Poolを使わずに実行した場合、結果は非決定的であるが、最悪の場合メモリを1GBアロケートする可能性があった。しかし、上の結果の通り、sync.Poolを使えば初めに確保した4KBのアロケーションと追加のアロケーション4KBの合計8KBで済んだ。
        Poolが便利なその他の場面としては、可能な限り素早く実行しなければならない操作のためにアロケート済みのオブジェクトを暖気する状況。この場合、生成されるオブジェクトの数を制限することでホストマシンのメモリを保護する代わりに、オブジェクトを作る時間を前倒しにすることによって消費者がオブジェクトの参照を得るまでの時間を短くしようとしている。この方法はリクエストに対して可能な限り素早くレスポンスしようとする高スループットのネットワークサーバーを書く場合、非常によく使われる。
        まず、サービスへの接続をシミュレートした関数を作る。
        接続には時間がかかるようにする。
        ```
            func connectToService() interface{} {
                time.Sleep(1*time.Second)
                return struct{}{}
            }
        ```

        次に各リクエストに対してサービスに新規接続を開始した場合、ネットワークサービスの性能がどれほどになるか見てみる。受け入れる接続それぞれに対して他のサービスへの接続を開くようなネットワークハンドラーを書く。ベンチマークを単純にするため、一度に1つの接続のみを許可する。
        ```
            func startNetworkDaemon() *sync.WaitGroup {
                var wg sync.WaitGroup
                wg.Add(1)
                go func() {
                    server, err := net.Listen("tcp", "localhost:8080")
                    if err != nil {
                        log.Fatalf("cannot listen: %v", err)
                    }
                    defer server.Close()

                    wg.Done()

                    for {
                        conn, err := server.Accept()
                        if err != nil {
                            log.Printf("cannot accept connection: %v", err)
                            continue
                        }
                        connectToService()
                        fmt.Fprintln(conn, "")
                        conn.Close()
                    }
                }()
                return &wg
            }
        ```
        このベンチマークを取ってみよう
        ```
            func init() {
                daemonStarted := startNetworkDaemon()
                daemonStarted.Wait()
            }

            func BenchmarkNetworkRequest(b *testing.B) {
                for i := 0; i < b.N; i++ {
                    conn, err := net.Dial("tcp", "localhost:8080")
                    if err != nil {
                        b.Fatalf("cannot dial host: %v", err)
                    }
                    if _, err := ioutil.ReadAll(conn); err != nil {
                        b.Fatalf("cannot read: %v", err)
                    }
                    conn.Close()
                }
            }
        ```

        結果は次の通り
        ```
            BenchmarkNetworkRequest-8   10                      1000385643  ns/op
            PASS     
            ok                          command-line-arguments  11.008s
        ```

        sync.Poolを使って架空のサービスへの接続をホストした場合
        ```
            func warmServiceConnCache() *sync.Pool {
                p := &sync.Pool {
                    New: connectToService,
                }
                for i := 0; i < 10; i++ {
                    p.Put(p.New())
                }
                return p
            }

            func startNetworkDaemon() *sync.WaitGroup {
                var wg sync.WaitGroup
                wg.Add(1)
                go func() {
                    connPool := warmServiceConnCache()

                    server, err := net.Listen("tcp", "localhost:8080")
                    if err != nil {
                        log.Fatalf("cannot listen: %v", err)
                    }
                    defer server.Close()

                    wg.Done()

                    for {
                        conn, err := server.Accept()
                        if err != nil {
                            log.Printf("cannot accept connection: %v", err)
                            continue
                        }
                        svcConn := connPool.Get()
                        fmt.Fprintln(conn, ")
                        connPool.Put(svcConn)
                        conn.Close()
                    }
                }()
                return &wg
            }
        ```

        結果はこのようになる。
        ```
            BenchmarkNetworkRequest-8   5000                    2904307 ns/op
            PASS
            ok                          command-line-arguments  32.647s
        ```

        3桁速くなっている。
        これまで見てきたように、オブジェクトプールデザインパターンは、オブジェクトを要求するけれどインスタンス化の後すぐにオブジェクトを捨ててしまう並行処理のプロセスがある場合、もしくはそうしたオブジェクトの生成がメモリに悪影響を与える場合に最適。
        しかしながらPoolを使うべきかを気を付けたほうが良いことが2つある。それは同型性とGetの呼び出し間の時間。
        まず1つ目について。もしPoolを扱うコードが同型でないものを扱うときは、初めからただインスタンス化するよりもPoolカラス得したものを変換するほうが時間がかかってしまうかもしれない。
        例えば、あなたのプログラムが任意の型の可変長のスライスを複数必要としている場合、Poolはあまり役立たない。その状況に適した長さのスライスをPoolから取得できる確率は低い。
        次に2つ目について。いかなる時でも、Goランタイムは今あるおぶっジェクトインスタンスの中からインスタンスを削除するかもしれない。ランタイムはガベージコレクションのサイクルの初めにプールの中身を消去するので、プログラム内でGetの呼び出し感覚が常に長いようだと、Poolのパフォーマンスはもはやその方のインスタンスを新しく作るよりも良いとは言えない。しかしながら、こうした動作は実装の細かな話であって、Poolの正しい利用方法に悪影響を与えるべきではない。最悪の場合、オブジェクトを普通に初期化するのとパフォーマンスの観点では全く変わらないかもしれないが、最良の場合に、Poolはこの上なく役に立つだろう。
        Poolを扱うときは次の点に気を付ける。
        - sync.Poolをインスタンス化するときは、呼び出されるときにスレッド安全なNewメンバー変数を用意する。
        - Getでインスタンスを取得するとき、受け取るオブジェクトの状態に関して何も想定してはいけない。
        - プールから取り出したオブジェクトの利用が終わったらPutを確実に呼ぶこと。さもなければ、Poolは役に立たない。通常はdeferを使ってこれを行う。
        - プール内のオブジェクトはおよそ均質なものであるべき。


- チャネル
    チャネルはHoareのCSPに由来する、Goにおける同期処理のプリミティブの1つ。メモリに対するアクセスを同期するのに使える一方で、ゴルーチン間の通信に使うのが最適
    水が流れる川のように、チャネルは情報の流れの水路として機能
    値はチャネルに沿って渡され、そこから下流に読み込まれる。
    このような理由から、通常chan型の変数名の末尾をStreamという後置語を付けたり、Chやcを付けたりする。
    チャネルを使うときは、値をchan型の変数に渡し、プログラムのどこか他の場所でその値をチャネルから読み込む。
    プログラムの全く異なる各部分はお互いが何をしているかは知らず、チャネルが存在しているメモリの中の同じ場所を参照している。
    プログラムの中でチャネルへの参照を渡すことでこうした実装ができる。
    ```
        var dataStream chan interface{}     //  1
        dataStream = make(chan interface{}) //  2
    ```
    1. チャネルを宣言する。宣言したのはからのインターフェース型なのでinterface{}「型の」チャネルだと書いている。
    2. ビルドインのmake関数を使ってチャネルを初期化している。

    チャネルは一方向だけにデータが流れるのようにも宣言できる。
    送信だけ、受信だけをするチャネルを定義できる。
    <-演算子を追加する

    【読み込み専用チャネルの宣言】
    ```
        var dataStream <-chan interface{}
        dataStream := make(<-chan interface{})
    ```

    【送信専用チャネルの宣言】
    ```
        var dataStream chan<- interface{}
        dataStream := make(chan<- interface{})
    ```

    ```
        var receiveChan <-chan interface{}
        var sendChan chan<- interface{}
        dataStream := make(chan interface{})

        //  正しい記述
        receiveChan = dataStream
        sendChan = dataStream
    ```
    チャンネルは型である。
    chan interface{} これはこのチャンネルにはどのような型のデータでも出し入れができるということ
    厳格な型を与えて扱うデータを制限することもできる。
    ```
        intStream := make(chan int)
    ```

    チャネルを使うには、再び<-演算子を使う。送信の場合は<-演算子をチャネルの右側に、受信の場合は<-演算子をチャネルの左側に置く。
    この演算子を他の味方をすると、データが演算子の矢印が指し示す方向に流れて変数に入るというように見える。
    ```
        stringStream := make(chan string)
        go func() {
            stringStream <- "Hello channels!"   //  1
        }()

        fmt.Println(<-stringStream)     //  2
    ```
    1. 文字列リテラルをstringStreamチャネルに渡す
    2. チャネルから文字列リテラルを読み込んでstdoutに表示する。

    結果は次の通り
    ```
        Hello channels!
    ```

    必要なのはチャネル変数だけで、そこを経由してデータの読み書きができる。
    しかしながら、読み込み専用チャネルにデータを書き込もうとしたり、書き込み専用チャネルから読み込もうとするとエラーになる。
    ```
        writeStream := make(chan<- interface{})
        readStream := make(<-chan interface{})

        <-writeStream
        readStream <- struct{}{}
    ```
    これをコンパイルしようとすると次のエラーが表示される。
    ```
        invalid operation: <-writeStream (receive from send-only type chan<- interface{})
        invalid operation: readStream <- struct {} literal (send to receive-only type <-chan interface {})
    ```

    これはGoの型システムによるもので、これのおかげでたとえ並行処理のプリミティブであっても型安全に扱える。
    これはAPIを宣言したり、また理解しやすい構成可能で論理的なプログラムを作る強力な方法。
    この賞の初めのほうで、ゴルーチンがスケジュールされたからと言って、プロセスが終了する前にそれが実行される保証はないと強調したことを思い出してください。それでもなお、先の例は実行できる完全な例で、コードも省略されていない正しい例なのです。匿名のゴルーチンがメインのゴルーチンが終わる前に完了できるのはなぜかきになったかもしれない。
    この例が動くのは、Goのチャネルはブロックするから。
    つまり、キャパシティがいっぱいのチャネルに書き込もうとするあらゆるゴルーチンは、チャネルに空きができるまで待機し、空のチャネルから読み込もうとしているあらゆるゴルーチンは少なくとも要素が1つ入るまで待機する。同様に無名ゴルーチンがstringStreamに文字列リテラルを書き込もうとしているため、子の書き込みが終わるまでゴルーチンは終了しない。したがって、メインゴルーチンと無名ゴルーチンは決定的にブロックする。
    もしプログラムを正しく書かないと、この状況はデッドロックを引き起こす。
    この例では無名ゴルーチンがチャネルに値を書き込むのを無意味な条件によって妨げている。
    ```
        stringStream := make(chan string)
        go func() {
            if 0 != 1 {         //  1
                return
            }
            stringStream <- "Hello channels!"
        }()
        fmt.Println(<-stringStream)
    ```
    1. stringStreamチャネルへの書き込みが決して起こらないようにしている

    このプログラムは次のようなエラーメッセージとともにパニックする。
    ```
        fatal error: all goroutines are asleep - deadlock!

        goroutine 1 [chan receive]:
        main.main()
            /tmp/babel-23079IVB/go-src-230795Jc.go:15 +0x97
        exit status 2
    ```
    メインゴルーチンはstringStreamチャネルに値が書き込まれるのを待ちますし、先ほどの無意味な条件によって、それは決して行われない。無名ゴルーチンが終了するとき、Ｇｏはすべてのゴルーチンが休止していることを検出し、デッドロックが発生していいることを報告する。

    <-演算子からの受信は、オプションとして2つの値を返すこともできる。
    ```
        stringStream := make(chan string)
        go func() {
            stringStream <- "Hello channels!"
        }()
        salutation, ok := <-stringStream        //  1
        fmt.Printf("(%v): %v", ok, salutation)
    ```

    次のような結果になる
    ```
        (true): Hello channels!
    ```

    2つ目の戻り値はプロセル内のどこかで書き込みがあったことで読み込み演算子が読み込み出来たかどうか、あるいは閉じたチャネルから生成されたデフォルトの値のいずれか

    閉じたチャネルとはなにか
    プログラムに置いて、もうこれ以上チャネルから値が送られてこないということを示せるのはとても便利。これによって下流のプロセスが先に進んでいいのか、終了していいのか、通信を新しいチャネルの、あるいは別のチャネルで再開していいのかといったタイミングを知ることができる。これはチャネルの型事に特別な値を用意することでも通知できるが、開発者がその都度そうした作業を行うのは冗長。また、そうした機能はチャネルに本来備わっているべきもので、データ型で解決すべきものではない。そうした意味で、チャネルを閉じるというのは、普遍的な見張りのようなもので「おい、上流はこれ以上値を書き込まないぞ、あとは好きにしろ」と教えてくれる。チャネルを閉じるには、次のようにcloseというキーワードを使う。
    ```
        valueStream := make(chan interface{})
        close(valueStream)
    ```
    面白いことに、閉じたチャネルからも読み込める。
    ```
        intStream := make(chan int)
        close(intStream)
        integer, ok := <- intStream     //  1
        fmt.Printf("(%v): %v", ok, integer)
    ```
    1. 閉じたチャネルから読み込む。

    結果は次の通り
    ```
        (false):    0
    ```

    このチャネルにはなにも書き込んでいなかったことに注意。
    それでも読み込み処理はできた。事実、チャネルは閉じれているにもかかわらず、やろうと思えば無制限にチャネルの書き込みを続けることができる。これは、あるチャネルに関して1つの上流の書き込みに対し、複数の下流での読み込みができるようにするため。
    2つ目の戻り値（ここではokという変数が保存されるが）はfalseで1つ目の戻り値である0はintのゼロ値であって、チャネルに書き込まれた値ではないことを示している。
    閉じたチャネルによっていくつか新しいパターンが使えるようになる。
    1つ目はチャネルをループで処理するもの。rangeキーワード（for文とともに使われるが）はチャネルを引数にとり、チャネルが閉じたときに自動的にループを終了する。これによってチャネル上の値を簡潔に繰り返し取得できる。
    ```
        intStream := make(chan int)
        go func() {
            defer close(intStream)      //  1
            for i := 1; i <= 5; i++ {
                intStream <- i
            }
        }()

        for integer := range intStream {    //  2
            fmt.Printf("%v ", integer)
        }
    ```
    1. ゴルーチンを抜ける前にチャネルを確実に閉じるようにする。
    2. instStreamをrangeする。

    次が出力結果、全ての値が出力されてからプログラムが終了している。
    ```
        1 2 3 4 5
    ```
    繰り返しが終了条件を必要としなかったことと、rangeは2つ目の真偽値の戻り値を返さないことに注意。
    繰り返し処理を簡潔に書くために、閉じたチャネルの扱いに関してはあなたの代わりにforが行ってくれる。
    また、チャネルが閉じることは、複数のゴルーチンに同時にシグナルを送信する方法の1つでもある。
    n個のゴルーチンが1つのチャネルを読み込んでいたら、各ゴルーチンのブロックを解除するためにチャネルにn回書き込まなくても、単純にチャネルを閉じるだけで済む。閉じたチャネルは無限に読み込めるので、読み込みを行うゴルーチンがいつくあっても問題がない。またチャネルを閉じるほうがn回書き込むよりもコストが低く、性能が良い。これは複数のゴルーチンを一度に開放する例
    ```
        begin := make(chan interface{})
        var wg sync.WaitGroup
        for i := 0; i < 4; i++ {
            wg.Add(1)
            go func (i int) {
                defer wg.Done()
                <-begin         //  1
                fmt.Printf("%v has begun\n", i)
            }(i)
        }

        fmt.Println("Unblocking goroutines...")
        close(begin)            //  2
        wg.Wait()
    ```
    1. ここでチャネルから読み込めるようになるまでゴルーチンは待機する。
    2. チャネルを閉じる。これによって全てのゴルーチンを同時に開放する。

    beginチャネルを閉じるまで土のゴルーチンも進まないことが分かると思う。
    ```
        2 has begun
        1 has begun
        0 has begun
        3 has begun
    ```
    バッファ付きチャネルを作ることもできる。
    これは初期化の際にキャパシティが与えられたチャネルを指す。
    つまり読み込みが一度も行われなくても、キャパシティがnのバッファ付きチャネルであればゴルーチンはn回まで書き込み可能
    ```
        var dataStream chan interface{}
        dataStream = make(chan interface{}, 4)      //  1
    ```
    1. キャパシティが4のバッファ付きチャネルを作る。このチャネルには読み込みが行われなくても、4回まで書き込み可能。

    ここでも、バッファ付きチャネルがバッファなしチャネルの宣言と何も違いがないことを説明したかったため、宣言と初期化を2行に分けて記述。
    チャネルを初期化するゴルーチンがそのチャネルにバッファがあるかどうかを管理している。
    ということは、チャネルを生成することで、おそらくそのチャネルの挙動と性能をより簡単に推測できるように、そこに書き込みをするゴルーチンと密に紐づけられているだろうということ。
    バッファ付きチャネルがあるということはバッファなしチャネルもある。
    バッファなしチャネルとは単純にバッファ付きチャネルでキャパシティが0のものを指す。
    同等の機能をもった2つのチャネルの例
    ```
        a := make(chan int)
        b := make(chan int, 0)
    ```
    2つのチャネルとともにintのチャネルでキャパシティはゼロ。
    ブロックについて話をしたときに、チャネルが満杯の時はチャネルへの書き込みによってブロックし、チャネルが空の時はチャネルからの読み込みによってブロックする。
    「満杯」や「空」というのはキャパシティの機能、つまりバッファサイズのこと。バッファなしチャネルのキャパシティはゼロなので書き込む前の段階ですでに満杯。受信する先がないバッファありチャネルでキャパシティが4のものは、4回書き込むと満杯になる、そして5回目の書き込みの際二はブロックする。なぜなら5つ目の要素を書き込む先がないから。バッファなしチャネルのように、バッファ付きチャネルもブロックする。事前条件としてチャネルがからか満杯化だけが違う。その意味で、バッファ付きチャネルは並行プロセスが通信するためのインメモリのFIFOキュー。
    ```
        c := make(chan rune, 4)
    ```
    論理的には、これによって4つのスロットがあるバッファを持ったチャネルが生成される。
    ```
        ■■■■
    ```
    このチャネルに書き込む
    ```
        c <- 'A'
    ```
    このチャネルの受信先がないときはAtoiuルーンはチャネルのバッファの先頭のスロットに配置される。
    ```
        A■■■
    ```
    以降、子のバッファ付きチャネルへの書き込みは（※読み込む先はない）、チャネル内の残りのスロットを順番に埋めていく
    ```
        c <- 'B'
    ```
    ```
        AB■■
    ```
    ```
        c <- 'C'
    ```
    ```
        ABC■
    ```
    ```
        c <- 'D'
    ```
    ```
        ABCD
    ```
    4回書き込むと、このキャパシティが4のバッファ付きチャネルは満杯になる。ここでのこのチャネルに再度書き込もうとするとどうなるか？
    ```
        ABCD←×E
    ```
    この書き込みをするゴルーチンはブロックされた。個のゴルーチンは別のゴルーチンがこのチャネルに対して読み込みを行ってバッファに空きができるまでブロックされ続ける。ではこのチャネルから読み込んでみよう
    ```
        A←BCDE
    ```
    ご覧の通り、個の読み込みによってチャネルの先頭に配置されていたルーンであるAが受信された。そして、ブロックされていた書き込みが解放され、Eがバッファの末尾に書き込まれた。
    また、バッファ付きチャネルが空で、かつそれに対する受信先がある場合、バッファはバイパスされ、値は送信元から受信先へと直接渡される。実際のところ、これは透過的に行われるが、バッファ付きチャネルの性能に関する性質として知っておいて損はない。
    バッファ付きチャネルは特定の状況では便利だが、気を付けて作らないといけない。バッファ付きチャネルは早すぎる最適化になりやすく、またデッドロックをおきにくくさせることで、結果的に見えないところに隠してしまうことになりえる。
    例
    ```
        var stdoutBuff bytes.Buffer         //  1
        defer stdoutBuff.WriteTo(os.Stdout) //  2

        intStream := make(chan int, 4)      //  3
        go func() {
            defer close(intStream)
            defer fmt.Fprintln(&stdoutBuff, "Producer Done.")
            for i := 0; i < 5; i++ {
                fmt.Fprintf(&stdoutBuff, "Sending: %d\n", i)
                intStream <- i
            }
        }()

        for integer := range intStream {
            fmt.Fprintf(&stdoutBuff, "Received %v.\n", integer)
        }
    ```
    1. インメモリのバッファを作って出力が非決定的になるのを軽減する。何の保証もないが、stdoutに直接書き込むより若干速い。
    2. プロセスが終了する前に確実にバッファがstdoutに書き込まれるようにする。
    3. キャパシティが4のバッファ付きチャネルを作成する。

    この例ではstdoutに出力される順番は非決定的。しかし、無名ゴルーチンがどのように動作しているかはおおよそ理解できると思う。出力結果を見れば、無名ゴルーチンが4つの結果全てをintStreamに書き込み、メインゴルーチンが1つ目の結果を読み込む前に終了していることが分かる。
    ```
        Sending: 0
        Sending: 1
        Sending: 2
        Sending: 3
        Sending: 4
        Producer Done.
        Received 0.
        Received 1.
        Received 2.
        Received 3.
        Received 4.
    ```

    これは正しい条件の下で役立つ最適化の例。チャネルに書き込みを行うゴルーチンが書き込む回数を事前に知っていたら、バッファ付きチャネルをこれから書き込む回数分のキャパシティだけ用意して、できる限り早く書き込みを行う。
    これまで、バッファなしチャネル、バッファ付きチャネル、双方向チャネル、単方向チャネルについてお話しした。チャネルに関して唯一お話ししていない話題は、チャネルのデフォルト値であるnilについて。プログラムはどのようにあnilチャネルを扱うのだろうか？
    ```
        var dataStream chan interface{}
        <- dataStream
    ```
    このプログラムは次のようなエラーメッセージとともにパニックを起こす。
    ```
        fatal error: all goroutines are asleep - deadlock!

        goroutine 1 [chan receive (nil chan)]:
        main.main()
            /tmp/babel-23079IVB/go-src-2307904q.go:9 +0x3f
        exit status 2
    ```
    デッドロック。nilチャネルからの読み込みは（必ずしもデッドロックを引き起こすわけではないが）プログラムをブロックすることを示している。
    書き込みに関してはどうだろうか
    ```
        var dataStream chan interface{}
        dataStream <- struct{}{}
    ```
    結果は次の通り。
    ```
        fatal error: all goroutines are asleep - deadlock!

        goroutine 1 [chan send (nil chan)]:
        main.main()
            /tmp/babel-23079IVB/go-src-23079dnD.go:9 +0x77
        exit status 2
    ```
    nilチャネルへの書き込みもブロックしてしまう。
    残りの操作はただ1つ、close
    もしnilチャネルを閉じたら何が起こるのだろうか
    ```
        var dataStream chan interface{}
        close(dataStream)
    ```
    結果は次の通り
    ```
        panic: close of nil channel
    ```
    デッドロックではなく、純粋にパニックを起こした。
    チャネルを扱うときは常に、まず確実に初期化をしておく。
    チャネルの扱いに関して多くの規則を学んだ。
    ```
        操作            チャネルの状態              結果
        読み込み        
                        nil                         ブロック
                        Openでから出ない            値を取得
                        Openで空                    ブロック
                        Close                       <デフォルト値>,false
                        書き込み専用                コンパイルエラー
        書き込み専用
                        nil                         ブロック
                        Openで満杯                  ブロック
                        Openで満杯ではない           値を書き込み
                        Close                       panic
                        読み込み専用                 コンパイルエラー
        close
                        nil                         panic
                        Openで空でない               チャネルを閉じる。読み込みはチャネルの中身がなくなるまで成功する。
                                                    その後読み込みはデフォルト値を読み込む
                        Openで空                     チャネルを閉じる。デフォルト値を読み込む
                        Closed                       panic
                        読み込み専用                  コンパイルエラー
    ```

    まず、チャネルを正しいコンテキストに入れるため初めにすべきことは、チャネルの所有権を割り振ること。
    ここでは所有権を、チャネルを初期化し、書き込み、閉じるゴルーチンとして定義する。ガベージコレクションがない言語でのメモリのように、プログラムで論理的に判断していくためには、土のゴルーチンがチャネルを所有しているかをはっきりさせることが重要。単方向チャネルを宣言することはチャネルを所有するゴルーチンとチャネルを利用するだけのゴルーチンを区別できるようにするための道具。チャネルを所有しているゴルーチンにはチャネルに対する書き込み権限（chanまたはchan<-）があり、チャネルを利用するだけのゴルーチンには読み込み専用権限（<-chan）しかない。チャネルの所有権と非所有権の区別をすれば、前述の表の結果に自然としたがうこととなる。そして、チャネルを所有するゴルーチンとそうでないゴルーチンそれぞれに責任を割り当てられるようになる。
    チャネルを所有するゴルーチンは次の手順を踏むべき。
    1. チャネルを初期化する。
    2. 書き込みをおこなうか、他のゴルーチンに所有権を渡す。
    3. チャネルを閉じる。
    4. 上の3つの手順をカプセル化して読み込みチャネルを経由して公開する。

    これらの責任をチャネルの所有者に与えることで、いくつかのことが起こる。
    - チャネルを初期化するゴルーチンなので、nilチャネルに書き込んでデッドロックしてしまう危険がなくなる。
    - チャネルを初期化するゴルーチンなので、nilチャネルを閉じることによっておこるpanicの危険がなくなる。
    - チャネルを閉じるタイミングを決めるゴルーチンなので、閉じたチャネルに書き込んでpanicになる危険がなくなる。
    - コンパイル時に型チェックを行って、チャネルに対する不適切な書き込みを防ぐ。

    読み込みの際に起こりうるブロックする操作について。チャネルの消費者として、2つだけ注意しなければならない。
    - チャネルがいつ閉じられたか把握する。
    - いかなる理由でもブロックする操作は責任をもって扱う。

    1つ目の点に関しては、単純に読み込み専用演算子から2つ㎡の戻り値を確認する。2つ目の点は定義するのがずっと難しい。なぜならプログラムのアルゴリズムに依存するから。タイムアウトさせたかったり、止めるように言われたら読み込みを止めたり、プロセスのライフタイムすべてでコンテンツをブロックしたりと、状況によってさまざまに変わる。大切なのは、消費者として、読み込みはブロックしうるという事実を扱うべきであるということ。

    今は、次の例をこれらの概念を理解する手助けとする。明確にチャネルを所有するゴルーチンと、チャネルをブロックと閉じることを扱う消費者を作成する。
    ```
        chanOwner := func() <- chan int{
            resultStream := make(chan int, 5)       //  1
            go func() {                             //  2
                defer close(resultStream)           //  3
                for i := 0; i <= 5; i++ {
                    resultStream <- i
                }
            }()
            return resultStream                     //  4
        }

        resultStream := chanOwner()
        for result := range resultStream {
            fmt.Printf("Received: %d\n", result)
        }
        fmt.Println("Done receiving!")
    ```
    1. バッファ付きチャネルを初期化する。結果を6つ生成するとわかっているので、ゴルーチンができる限り早く完了するようにキャパシティが5のバッファ付きチャネルを作成する。
    2. resultStreamへの書き込みを行う無名ゴルーチンを起動する。ゴルーチンよりも先にチャネルを生成したことに注意。外の関数によってカプセル化されている。
    3. resultStreamを使い終わった後に確実に閉じられるようにしている。これはチャネルの所有者としての責任。
    4. チャネルを返す。戻り値は読み込み専用チャネルとして宣言されているので、resultStreamは暗黙的に読み込み専用の消費者に変換される。
    5. resultStreamをrangeで繰り返す。消費者として、チャネルのブロックとチャネルを閉じたことだけに注意する。

    実行すると次のような結果となる。
    ```
        Received: 0
        Received: 1
        Received: 2
        Received: 3
        Received: 4
        Received: 5
        Done receiving!
    ```
    resultStreamチャネルのライフサイクルがchanOwner関数の中でどのようにカプセル化されているかお分かりになっただろうか。nilチャネルあるいは閉じたチャネルに書き込みが発生しないことはとても明快。
    そしてチャネルを閉じる作業は常に1度しかない。
    これはプログラムからリスクを取り除いてくれる。
    こうしたことを自明に保つために、プログラム内はできる限りチャネルの所有権のスコープは小さくすることを強くお勧めする。
    多数のメソッドをもつ構造体のメンバー変数にチャネルがあると、そのチャネルがどのようにふるまうかがすぐに不明瞭になる。
    消費者の関数は読み込みチャネルへのアクセス権しかもっていない。それゆえに、消費者の関数はブロックする読み込みとチャネルの閉じ方をどのように扱うか知っておく必要がある。
    この小さな例では、チャネルが閉じられるまでプログラム全体をブロックしても全く問題ない、という方針をとった。
    もしこの原則に従うべくコードを書いているのであれば、システムで何が起きているか推測するのがずっと簡単になるし、システムがより期待通りに動作するようになる。絶対にデッドロックやパニックが発生しないとは言い切れないが、発生した場合には、おそらくチャネル所有権のスコープが大きすぎたか、所有権が不明瞭になっていたと気付くと思う。
    ゴルーチンとクロージャーの単純さを組み合わせると、きれいで正しくて平行なコードを書くのがどれほど簡単になるかは明らかである。

- select文
    select文はチャネルをまとめる糊。これによってプログラム内でより大きな抽象化をするためにチャネルを組み合わせられる。チャネルがゴルーチンを結びつける糊だとしたら、select文はどう表現すればよいか？select文は並行処理があるGoのプログラムに置いて、最重要要素であるといっても過言ではない。select文は、単一の関数や型の中でチャネルを局所的に紐づけていたり、またシステム内のいくつかのコンポーネントを大局的に紐づけていたりと様々なところで見つけられる。select文はコンポーネントを組み合わせるだけでなく、プログラム内でのこうした接合部でキャンセル処理、タイムアウト、待機、デフォルト値といった概念とチャネルを安全にまとめられる。
    逆にselect文がプログラムで補助的にしか使われておらず、もっぱらチャネルのみを扱っている場合、プログラム内のコンポーネントをお互いにどうやって組み合わせるのだろうか。
    この強力なselect文とはいったい何なのか。どのように使い、どのように動作するのか。
    ```
        var c1, c2 <-chan interface{}
        var c3 chan<- interface{}
        selec {
            case <- c1:
                //  何かをする
            case <- c2:
                //  何かをする
            case <- c3:
                //  何かをする
        }
    ```
    switchブロックに見た目が似ている。switchブロックのように、selectブロックは複数の文がガードされたcase文に追われている。似ているのはそれだけ。switchブロックと違い、selectブロックのcase文は上から順番に評価されない。また1つも条件に該当しない場合には自動的に実行されない。
    代わりに、読み込みや書き込みのチャネルはすべて同時に取り扱われ、どれが用意できたかを確認する。
    つまり、読み込みの場合はチャネルに書き込みがあったり閉じられたりしたか、書き込みの場合はキャパシティいっぱいになっていないものはないか確認する。どのチャネルも準備できていない場合には、select全体がブロックする。チャネルが1つでも準備完了したら、その操作が行われ、対応する文が実行される。
    ```
        start := time.Now()
        c := make(chan interface{})
        go func() {
            time.Sleep(5*time.Second)
            close(c)    //  1
        }()

        fmt.Println("Blocking on read...")
        select {
        case <- c:      //  2
            fmt.Printf("Unblocked %v later.\n", time.Since(start))
        }
    ```
    1. 5秒待った後にチャネルを閉じる。
    2. チャネルの読み込みを試みる。このようにコードがかかれているが、実際にはselect文は必要ないことに注意。この場合は単純に<-cと書けるが、後ほどこの例を拡張していくのでこのように書いている。

    実行すると次のような結果になる。
    ```
        Blocking on read...
        Unblocked 5.000170047s later.
    ```

    疑問
    - 複数のチャネルが読み込んでいる場合は何が起きるのか。
    - もしどのチャネルも準備完了しなかったらどうなるか。
    - もしどのチャネルも準備完了になっていないときに何かしたい場合はどうか。

    ```
        c1 := make(chan interface{}); close(c1)
        c2 := make(chan interface{}); close(c2)

        var c1Cound, c2Cound int
        for i := 1000; i >= 0; i-- {
            select {
            case <- c1:
                c1Count++
            case <- c2:
                c2Count++
            }
        }
        fmt.Printf("c1Count : %d\nc2Count: %d\n", c1Count, c2Count)
    ```

    結果はこうなる。
    ```
        c1Count: 505
        c2Count: 496
    ```

    select文での半分の時間はc1空の読み込みに、もう半分の時間はc2空の読み込みに使われた。
    興味深い結果で、偶然過ぎるように見える。事実、偶然。
    Goのラインタイムはcase文全体に対して疑似乱数による一葉選択をしている。つまり、case文全体では、それぞれの条件が等しく選択される可能性がある。
    Goのランタイムはあなたが書いたselect文の意味を何一つ知りえない。つまり、Goのラインタイムはあなたの問題空間やあなたがselect文でチャネルをまとめた理由を推測できない。こうした理由から、Goのランタイムが実現したいと思っている最善の状態は、それぞれの条件にならして実行すること。それを実現する良い方法として、乱数を導入すること。この場合、どのチャネルから読み込むかの選択。各チャネルが使われる確率を等しくすることで、select文を使うすべてのGoプログラムは各条件を鳴らして実行する。
    2つ目の疑問に関して。1つも読み込みができるようにならなかった場合にどうなるのか。全てのチャネルがブロックされたときに何もやることがない場合、永遠にブロックし続けるわけにもいかないのでおそらくタイムアウトさせたいと思う。Goのtimeパッケージはselect文のパラダイムの中でうまく適用できるチャネルを使った洗練されたやり方を提供している。
    ```
        var c <-chan int
        select {
            case <-c:       //  1
            case <-time.After(1*time.Second):
                fmt.Println("Timed out.")
        }
    ```
    1. このcase文はnilチャネルから読み込んでいるので決してブロックが解放されない。
    これは次のような結果になる。
    ```
        Timed out.
    ```

    time.After関数はtime.Durationを引数に撮り、与えた期間経過後の現在時刻を送信するチャネルを返す。これがselectでタイムアウトを実現する簡潔な方法として使える。
    まだ疑問は残る。
    チャネルが1つも読み込めず、その間に何かする必要がある場合にはどうしたらよいか。
    case文のようにselect文にも、選択しているすべてのチャネルがブロックしているときに何かしたい場合のためにdefault節が用意されている。
    ```
        start := time.Now()
        var c1, c2 <-chan int
        select {
        case <-c1:
        case <-c2:
        default:
            fmt.Printf("In default after %v\n\n", time.Since(start))
        }
    ```
    これは次のような結果となる。
    ```
        In default after 1.421us
    ```
    見てわかる通り、この例でdefault文はほぼ瞬間的に実行された。
    これでselect文をブロックすることなく終了できる。
    通常、default節はfor-selectループの中で使われているものを見かける。これによってゴルーチンの結果を待つ間に他のゴルーチンで仕事を進められる。
    ```
        done := make(chan interface{})
        go func() {
            time.Sleep(5*time.Second)
            close(done)
        }()

        workCounter := 0
        loop:
        for {
            select {
            case <-done:
                break loop
            default:
            }

            //  Simulate work
            workCounter++
            time.Sleep(1*time.Second)
        }

        fmt.Printf("Achieved %v cycles of work before signalled to stop.\n", workCounter)
    ```
    この場合、ループは何かの仕事をしていて、ときおり止めるべきかどうかを確認している。
    
    最後に空select文という特別な状況を紹介する。これはcase節がないselect文のことを指す。
    次のような見た目となる。
    ```
        select {}
    ```
    このselect文は永遠にブロックする。
